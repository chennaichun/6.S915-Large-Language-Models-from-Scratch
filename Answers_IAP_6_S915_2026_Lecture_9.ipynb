{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1zNXSnazStppTd7NEl_8CP2ehCzkgqBcp","timestamp":1768504026393},{"file_id":"1wi94f6O9o1bdhoADpshouO39cuqt1LNy","timestamp":1768480391022}],"collapsed_sections":["7zjPns5IGZjD","fjK9ZFBAgQ3m","fveDkvZlESLL"],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyNKcWU51S7JzbwVqSvrSJ0R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# GPT-2 to Llama 2"],"metadata":{"id":"7zjPns5IGZjD"}},{"cell_type":"markdown","source":["We will be creating Llama 2 while also using our knowledge from GPT-2."],"metadata":{"id":"HShVT4ErHcep"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"NVMLk1QDIZaA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Config dictionary:"],"metadata":{"id":"ql73HsISL2KK"}},{"cell_type":"code","source":["LLAMA2_CONFIG_7B = {\n","    \"vocab_size\": 32000,     # Vocabulary size\n","    \"context_length\": 4096,  # Context length\n","    \"emb_dim\": 4096,         # Embedding dimension\n","    \"n_heads\": 32,           # Number of attention heads\n","    \"n_layers\": 32,          # Number of layers\n","    \"hidden_dim\": 11008,     # NEW: Size of the intermediate dimension in FeedForward\n","    \"dtype\": torch.bfloat16  # NEW: Lower-precision dtype to reduce memory usage\n","}"],"metadata":{"id":"pq_r6nINL6D4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Llama 2 uses RMSNorm instead of LayerNorm."],"metadata":{"id":"ch-r1xK6Ggje"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1_cJLzR2gqZ"},"outputs":[],"source":["class RMSNorm(torch.nn.Module):\n","    def __init__(self, config, eps=1e-8):\n","        super().__init__()\n","        self.scale = nn.Parameter(torch.ones(config[\"emb_dim\"]))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        # Normalize by RMS over the last dimension\n","        # May be helpful: x.pow(2) and torch.sqrt\n","        rms = torch.sqrt(x.pow(2).mean(dim=-1, keepdim=True) + self.eps)\n","        return x / rms * self.scale"]},{"cell_type":"markdown","source":["Llama 2 uses SiLU instead of GELU.\n","\n","$SiLU(x) = \\sigma(x) \\cdot x$ where $\\sigma(x) = 1 / (1 + e^{-x})$"],"metadata":{"id":"XIGRERw9GlxH"}},{"cell_type":"code","source":["a = torch.tensor([5.3, 7.2, -1.1, 2.0])\n","silu = nn.SiLU()\n","print(silu(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwimqsEDGRjG","executionInfo":{"status":"ok","timestamp":1768510729250,"user_tz":300,"elapsed":8,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"bec7a564-f922-46ca-c60f-3fbcd48d4ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 5.2737,  7.1946, -0.2747,  1.7616])\n"]}]},{"cell_type":"markdown","source":["The feed forward network also uses a linear layer that operates parallel to the first linear layer. In the diagram, the dot in the middle is element-wise multiplication. Linear 1 and Linear 2 map to a hidden dimension specified in the config."],"metadata":{"id":"RkoEOJrbKjFl"}},{"cell_type":"markdown","source":["![Screenshot 2026-01-15 at 5.17.30â€¯AM.png](data:image/png;base64,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)"],"metadata":{"id":"SlJZPFrfKNos"}},{"cell_type":"markdown","source":["**Exercise 1:** Complete the feed forward network for Llama 2. For the linear layers, use `dtype=config[\"dtype\"]` and `bias=False`."],"metadata":{"id":"BKtwl9jALFWW"}},{"cell_type":"code","source":["class FeedForward(torch.nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        # TODO\n","        self.linear1 = nn.Linear(config[\"emb_dim\"], config[\"hidden_dim\"],\n","                                 dtype=config[\"dtype\"], bias=False)\n","        self.linear2 = nn.Linear(config[\"emb_dim\"], config[\"hidden_dim\"],\n","                                 dtype=config[\"dtype\"], bias=False)\n","        self.silu = nn.SiLU()\n","        self.linear3 = nn.Linear(config[\"hidden_dim\"], config[\"emb_dim\"],\n","                                 dtype=config[\"dtype\"], bias=False)\n","\n","\n","    def forward(self, x):\n","        # TODO\n","        x1 = self.linear1(x)\n","        x1 = self.silu(x1)\n","        x2 = self.linear2(x)\n","        x = x1 * x2\n","        x = self.linear3(x)\n","        return x"],"metadata":{"id":"KeHBB8phLElC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Llama uses RoPE position embeddings. In addition to using position indices (`torch.arange`), RoPE applies a rotary transformation which uses sin and cos. RoPE takes in an input `x` and outputs an embedding of `x` that includes the position information.\n","\n","RoPE replaces position embeddings in the model."],"metadata":{"id":"A3oIiIkuIt5M"}},{"cell_type":"code","source":["def precompute_rope_params(head_dim, theta_base=10_000, context_length=4096):\n","    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n","\n","    # Compute the inverse frequencies\n","    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2)[: (head_dim // 2)].float() / head_dim))\n","\n","    # Generate position indices\n","    positions = torch.arange(context_length)\n","\n","    # Compute the angles\n","    angles = positions.unsqueeze(1) * inv_freq.unsqueeze(0)  # Shape: (context_length, head_dim // 2)\n","\n","    # Expand angles to match the head_dim\n","    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n","\n","    # Precompute sine and cosine\n","    cos = torch.cos(angles)\n","    sin = torch.sin(angles)\n","\n","    return cos, sin\n","\n","def compute_rope(x, cos, sin):\n","    # x: (batch_size, num_heads, seq_len, head_dim)\n","    batch_size, num_heads, seq_len, head_dim = x.shape\n","    assert head_dim % 2 == 0, \"Head dimension must be even\"\n","\n","    # Split x into first half and second half\n","    x1 = x[..., : head_dim // 2]  # First half\n","    x2 = x[..., head_dim // 2 :]  # Second half\n","\n","    # Adjust sin and cos shapes\n","    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n","    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n","\n","    # Apply the rotary transformation\n","    rotated = torch.cat((-x2, x1), dim=-1)\n","    x_rotated = (x * cos) + (rotated * sin)\n","\n","    return x_rotated.to(dtype=x.dtype)"],"metadata":{"id":"VIiC0sEPROnj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example of using RoPE:"],"metadata":{"id":"dFm5VhtCSVb3"}},{"cell_type":"code","source":["# Settings\n","batch_size = 2\n","context_len = 5\n","num_heads = 4\n","head_dim = 16\n","\n","# Instantiate RoPE parameters\n","cos, sin = precompute_rope_params(head_dim=head_dim, context_length=context_len)\n","\n","# Dummy query and key tensors\n","torch.manual_seed(123)\n","queries = torch.randn(batch_size, num_heads, context_len, head_dim)\n","keys = torch.randn(batch_size, num_heads, context_len, head_dim)\n","\n","# Apply rotary position embeddings\n","queries_rot = compute_rope(queries, cos, sin)\n","keys_rot = compute_rope(keys, cos, sin)"],"metadata":{"id":"rQJRDhh6SQwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In GPT, the positional embeddings were added to the token embeddings. In Llama, RoPE is applied to the keys and queries (not values) in the attention module.\n","\n","Some other differences:\n","\n","\n","*   Llama's attention doesn't have `qkv_bias`\n","*   dtype setting\n","*   no dropout\n","\n"],"metadata":{"id":"9iPnD4hrYaBY"}},{"cell_type":"markdown","source":["**Exercise 2:** Add RoPE to the `MultiHeadAttention` module."],"metadata":{"id":"5Azih-LBakOo"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.d_in = config[\"emb_dim\"]\n","        self.d_out = config[\"emb_dim\"]\n","        self.num_heads = config[\"n_heads\"]\n","        self.d_head = self.d_out // self.num_heads # Dimension of each head\n","        self.context_length = config[\"context_length\"]\n","        self.W_query = nn.Linear(self.d_in, self.d_out, bias=False, dtype=config[\"dtype\"])\n","        self.W_key = nn.Linear(self.d_in, self.d_out, bias=False, dtype=config[\"dtype\"])\n","        self.W_value = nn.Linear(self.d_in, self.d_out, bias=False, dtype=config[\"dtype\"])\n","\n","        causal_mask = torch.tril(torch.ones(self.context_length, self.context_length))\n","        self.projection = nn.Linear(self.d_out, self.d_out, bias=False, dtype=config[\"dtype\"])\n","        # no dropout\n","\n","        self.register_buffer(\"mask\", causal_mask)\n","\n","        # TODO: Initialize cos and sin from RoPE\n","        cos, sin = precompute_rope_params(head_dim=self.d_head, context_length=self.context_length)\n","        self.register_buffer(\"cos\", cos)\n","        self.register_buffer(\"sin\", sin)\n","\n","    def forward(self, x):\n","        B, N, D = x.shape\n","        Q = self.W_query(x)\n","        K = self.W_key(x)\n","        V = self.W_value(x)\n","\n","        Q = Q.view(B, N, self.num_heads, self.d_head).transpose(1, 2)\n","        K = K.view(B, N, self.num_heads, self.d_head).transpose(1, 2)\n","        V = V.view(B, N, self.num_heads, self.d_head).transpose(1, 2)\n","\n","        # TODO: Apply RoPE\n","        Q = compute_rope(Q, self.cos, self.sin)\n","        K = compute_rope(K, self.cos, self.sin)\n","\n","        QKT = Q @ K.transpose(2, 3)\n","        masked_QKT = QKT.masked_fill(self.mask[:N, :N] == 0, float('-inf'))\n","        # [:N, :N] is because N could be less than context length\n","        # due to lack of words in the data\n","        attention_probs = torch.softmax(masked_QKT / (self.d_head ** 0.5), dim=-1)\n","\n","        context_vector = attention_probs @ V\n","        context_vector = context_vector.transpose(1, 2).contiguous().view(B, N, self.d_out)\n","        return self.projection(context_vector)"],"metadata":{"id":"u_OBAyV9oQ7U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `TransformerBlock` module uses RMSNorm instead of LayerNorm, and it also doesn't have a dropout."],"metadata":{"id":"qBf7wBg9biq9"}},{"cell_type":"markdown","source":["**Exercise 3:** Transform the GPT transformer block into a Llama 2 transformer block."],"metadata":{"id":"HJvUPZpOb0lB"}},{"cell_type":"code","source":["# TODO: Turn into a Llama 2 transformer block\n","class TransformerBlock(torch.nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        # TODO: Make necessary changes to __init__\n","        self.norm1 = RMSNorm(config)\n","        self.attn = MultiHeadAttention(config)\n","        self.ff = FeedForward(config)\n","        self.norm2 = RMSNorm(config)\n","\n","    def forward(self, x):\n","        # TODO: x -> norm 1 -> attention -> residual connection\n","        saved_x = x\n","        x = self.norm1(x)\n","        x = self.attn(x)\n","        x = saved_x + x # residual connection\n","\n","        # TODO: x -> norm 2 -> feed forward -> residual connection\n","        saved_x = x\n","        x = self.norm2(x)\n","        x = self.ff(x)\n","        x = saved_x + x # residual connection\n","\n","        return x"],"metadata":{"id":"V_wSPz4beCwb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For our Llama module, we can take our GPT module and make several changes:\n","\n","*   No position embedding (since we already had RoPE in our `MultiHeadAttention` module)\n","*   No dropout\n","*   Use RMSNorm instead of LayerNorm for our final norm\n","\n"],"metadata":{"id":"Pfwe9iUhcqio"}},{"cell_type":"markdown","source":["**Exercise 4:** Transform our GPT module into a Llama2 module."],"metadata":{"id":"Tm5YO0uSddI6"}},{"cell_type":"code","source":["# TODO: Rename module\n","# TODO: Remove position embeddings and dropout\n","# TODO: Use RMSNorm instead of LayerNorm\n","# TODO: config[\"emb_dim\"] instead of config[\"n_embd\"]\n","class Llama2(torch.nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.token_embedding = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"])\n","        self.blocks = nn.Sequential(*[TransformerBlock(config)\n","                                    for _ in range(config[\"n_layers\"])]) # Transformer blocks\n","        # f(*[2, 3, 5, 7]) means f(2, 3, 5, 7)\n","        self.norm_f = RMSNorm(config) # Final layer norm\n","        self.prediction_layer = nn.Linear(config[\"emb_dim\"], config[\"vocab_size\"])\n","        # Linear mapping to vocab size\n","\n","    def forward(self, x):\n","        B, N = x.shape      # B is batch size, N is context length\n","        token_embeddings = self.token_embedding(x)  # [B, N, n_embd]\n","        x = token_embeddings  # Full embeddings; [B, N, n_embd]\n","        x = self.blocks(x)  # Apply transformer blocks; [B, N, n_embd]\n","        x = self.norm_f(x) # Final RMS norm\n","        logits = self.prediction_layer(x)   # [B, N, vocab_size]\n","        return logits"],"metadata":{"id":"M9rlQerJeewi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Key differences between Llama 2 and GPT:\n","\n","1. Llama 2 uses RoPE instead of regular position embeddings. RoPE is applied to the `MultiHeadAttention` module, whereas regular position embedding in GPT-2 is applied before the transformer blocks in the same place as the token embeddings.\n","2. Llama 2 uses a different feed forward network. In the feed forward for Llama 2, we have an extra linear (with no activation) in parallel with our first linear and activation.\n","3. Llama 2 uses SiLU instead of GPT's GELU.\n","4. Llama 2 uses RMSNorm instead of LayerNorm.\n","5. Llama 2 doesn't use dropout.\n","6. Llama 2 doesn't have bias in its linear layers.\n","7. Llama 2 has dtype config."],"metadata":{"id":"QnYhYp5dO_Iu"}},{"cell_type":"markdown","source":["Initializing a Llama2-7B model:"],"metadata":{"id":"Q6BqNSinfXpr"}},{"cell_type":"code","source":["LLAMA2_CONFIG_7B = {\n","    \"vocab_size\": 32000,     # Vocabulary size\n","    \"context_length\": 4096,  # Context length\n","    \"emb_dim\": 4096,         # Embedding dimension\n","    \"n_heads\": 32,           # Number of attention heads\n","    \"n_layers\": 32,          # Number of layers\n","    \"hidden_dim\": 11008,     # NEW: Size of the intermediate dimension in FeedForward\n","    \"dtype\": torch.bfloat16  # NEW: Lower-precision dtype to reduce memory usage\n","}\n","# model = Llama2(LLAMA2_CONFIG_7B)"],"metadata":{"id":"QJGRBA65fGOy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Llama 2 (No exercises)"],"metadata":{"id":"fjK9ZFBAgQ3m"}},{"cell_type":"markdown","source":["Llama 2 uses sentencepiece instead of tiktoken. However, you need to accept a license agreement and await aproval in order to get the tokenizer or model parameters.\n","\n","If we were to load pretrained parameters, we would need to use the exact same tokenizer. We will train from scratch so we can just use tiktoken."],"metadata":{"id":"gtTiZXsOjY7H"}},{"cell_type":"code","source":["import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"vR5kQ9jjj9rZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Our dataset and dataloader functions:"],"metadata":{"id":"xdSQ52SsK9sY"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","# Dataset class\n","class MyData(Dataset):\n","    # Init function, called when the dataset is created\n","    # dataset = MyData(text, tokenizer, context_length=4, stride=1)\n","    def __init__(self, text, tokenizer, context_length, stride=1):\n","        self.input_ids = []\n","        self.target_ids = []\n","        token_ids = tokenizer.encode(text)\n","        for i in range(0, len(token_ids) - context_length, stride):\n","            self.input_ids.append(torch.tensor(token_ids[i : i + context_length]))\n","            self.target_ids.append(torch.tensor(token_ids[i + 1 : i + context_length + 1]))\n","\n","    # Length function\n","    # len(dataset)\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    # Get item function\n","    # dataset[idx]\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]\n","\n","def create_dataloader(text, batch_size, context_length, stride, shuffle=True, drop_last=True, num_workers=0):\n","    tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","    # Create the dataset object\n","    dataset = MyData(text, tokenizer, context_length, stride)\n","\n","    # Use the DataLoader library to create a dataloader that batches the data\n","    dataloader = DataLoader(dataset,\n","                            batch_size=batch_size,\n","                            shuffle=shuffle,\n","                            drop_last=drop_last,\n","                            num_workers=num_workers)\n","\n","    return dataloader"],"metadata":{"id":"Qzeqgdvt-0cj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cross entropy loss function used to train the model."],"metadata":{"id":"oX1S2tpxLT2n"}},{"cell_type":"code","source":["def calculate_loss(dataloader, model, device=\"cpu\", num_batches=None): # 1 epoch average loss\n","    # number of batches in dataset is not included as a dimension in any tensor\n","    if num_batches is None:\n","        num_batches = len(dataloader)\n","    else:\n","        num_batches = min(num_batches, len(dataloader))\n","    model.eval()\n","    total_loss = 0.0\n","    for i, (input, target) in enumerate(dataloader): # i is batch index\n","        if i >= num_batches:\n","            break\n","\n","        input = input.to(device) # Move input to appropriate device\n","        logits = model(input) # Obtain output logits of the model\n","        target = target.to(device) # Move target to appropriate device\n","\n","        loss = nn.functional.cross_entropy(logits.flatten(0, 1), target.flatten()) # Use cross entropy loss\n","        # cross_entropy takes in 2D tensor for logits\n","        # and 1D tensor for targets\n","\n","        total_loss += loss.item()\n","        # .item() extracts a numerical value from a 0D scalar tensor\n","    return total_loss / num_batches # len(dataloader) is number of batches"],"metadata":{"id":"U4tp7pTy_3gN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Useful helper function that can convert text into token IDs:"],"metadata":{"id":"A31_43RsNf3t"}},{"cell_type":"code","source":["def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text)\n","    return torch.tensor(encoded).unsqueeze(0) #unsqueeze adds batch dimension 1"],"metadata":{"id":"CcXFocHu7ptL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Our text generation function (with top k and temperature):"],"metadata":{"id":"UlAmsEkim730"}},{"cell_type":"code","source":["def generate_text_sample(model, idx, max_new_tokens, context_length,\n","                         temperature=0, top_k=3, eos_id=50256):\n","    epsilon = 1e-8\n","    if temperature == 0: # Preventing division by 0\n","        top_k = 1\n","\n","    # max_new_tokens is the number of tokens we want to generate\n","    # idx is the array of indices in the current context\n","    # idx has size [batch_size, n_tokens]\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_length:]     # Takes the latest context window\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]       #   last token in new context window\n","\n","        # for each word, we generate vector of probabilities\n","        # Every effort moves you\n","        # vocabulary: [closer, every, effort, forward, inches, moves, pizza, toward, you]\n","        # probs:      [  0.06,  0.01,   0.00,    0.85,   0.01,  0.01,  0.02,   0.03, 0.01]\n","        # argmax always only chooses largest probability value (e.g. forward), whereas\n","        # multinomial can have some variation (e.g. forward 85% of the time)\n","        # We want top_k to eliminate garbage like \"Every effort moves you pizza\"\n","        # top_k=3:\n","        # probs:      [  0.06,     0,      0,    0.85,      0,     0,     0,   0.03,    0]\n","        top_logits, top_indices = torch.topk(logits, k=top_k)\n","        min_val_in_topk = top_logits[:, [-1]] # Get the minimum value among the top_k logits for each sample in the batch\n","        new_logits = torch.where(\n","            condition=logits < min_val_in_topk, # Compare logits with the minimum value\n","            input=torch.tensor(float('-inf'), device=logits.device), # Ensure the tensor is on the correct device\n","            other=logits\n","        )\n","\n","        # Temperature:\n","        # low temperature = low variation (since logits will be high before softmax)\n","        # high temperature = high variation (since logits will be low before softmax)\n","        if temperature > epsilon:\n","            new_logits = new_logits / temperature\n","\n","        top_probs = torch.softmax(new_logits, dim=-1)\n","        idx_next = torch.multinomial(top_probs, num_samples=1)\n","        if idx_next == eos_id:\n","            break\n","\n","        idx = torch.cat((idx, idx_next), dim=1)     # dim=1 for the context window\n","    return idx"],"metadata":{"id":"LzbU0-ZAm-xO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper function used to generate and print the output:"],"metadata":{"id":"0Qju4Bm-Nlzn"}},{"cell_type":"code","source":["def generate_and_print_sample(model, tokenizer, device, start_context, max_new_tokens=50,\n","                              temperature=0, top_k=3, eos_id=50256):\n","    model.eval()\n","    context_size = model.blocks[0].attn.context_length\n","    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n","    with torch.no_grad():\n","        token_ids = generate_text_sample(model, encoded, max_new_tokens, context_size,\n","                                         temperature=temperature, top_k=top_k, eos_id=50256)\n","    decoded = tokenizer.decode(token_ids[0].squeeze(0).tolist())\n","    print(decoded.replace(\"\\n\", \" \"))\n","    model.train()"],"metadata":{"id":"Vo0LG-lU6z0w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper function used to get loss values for the train and validation splits:"],"metadata":{"id":"1_rqvtRkNz4b"}},{"cell_type":"code","source":["def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","    model.eval()\n","    with torch.no_grad():\n","        train_loss = calculate_loss(train_loader, model, device, eval_iter)\n","        val_loss = calculate_loss(val_loader, model, device, eval_iter)\n","    model.train()\n","    return train_loss, val_loss"],"metadata":{"id":"FnFLd7YV_rne"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Learning rate scheduler:"],"metadata":{"id":"LRU0pMdYa4bO"}},{"cell_type":"code","source":["from torch.optim.lr_scheduler import LambdaLR\n","import math\n","\n","def create_scheduler(optimizer, config):\n","    warmup_steps = int(config.get(\"warmup_steps\", 0))\n","    total_steps = int(config.get(\"total_steps\", 1))\n","\n","    def lr_lambda(step):\n","        if warmup_steps > 0 and step < warmup_steps:\n","            return step / max(1, warmup_steps)\n","        # cosine decay after warmup\n","        progress = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n","        progress = min(max(progress, 0.0), 1.0)\n","        return 0.5 * (1.0 + math.cos(math.pi * progress))\n","\n","    return LambdaLR(optimizer, lr_lambda)"],"metadata":{"id":"qewbXzgybJil"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helpers for saving and loading checkpoints:"],"metadata":{"id":"vw9jxlCcb-oN"}},{"cell_type":"code","source":["import os\n","\n","def save_checkpoint(path, model, optimizer, scheduler, my_config, global_step, epoch):\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    torch.save({\n","        \"model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","        \"scheduler\": scheduler.state_dict() if scheduler is not None else None,\n","        \"config\": my_config,\n","        \"global_step\": global_step,\n","        \"epoch\": epoch,\n","    }, path)\n","\n","def load_checkpoint(path, model, optimizer=None, scheduler=None, device=\"cpu\"):\n","    ckpt = torch.load(path, map_location=device)\n","    model.load_state_dict(ckpt[\"model\"])\n","    if optimizer is not None:\n","        optimizer.load_state_dict(ckpt[\"optimizer\"])\n","    if scheduler is not None and ckpt.get(\"scheduler\") is not None:\n","        scheduler.load_state_dict(ckpt[\"scheduler\"])\n","    return ckpt"],"metadata":{"id":"S3aFim3ocUKE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training loop with checkpointing, learning rate scheduler, and gradient clipping:"],"metadata":{"id":"d5GYNKWKN64S"}},{"cell_type":"code","source":["def training_loop(model, train_dataloader, val_dataloader,\n","                  optimizer, device, num_epochs,\n","                  eval_freq, eval_iter, start_context, tokenizer, config,\n","                  scheduler=None, ckpt_dir=\"checkpoints\", ckpt_freq=20,\n","                  resume_path=None):\n","    train_losses, val_losses, track_tokens_seen = [], [], []\n","    tokens_seen, global_step = 0, -1\n","    start_epoch = 0\n","    if resume_path is not None:\n","        ckpt = load_checkpoint(resume_path, model, optimizer, scheduler, device=device)\n","        global_step = ckpt.get(\"global_step\", global_step)\n","        start_epoch = ckpt.get(\"epoch\", 0)\n","        print(f\"Resumed from {resume_path} (epoch={start_epoch}, step={global_step})\")\n","\n","    for epoch in range(start_epoch, num_epochs):\n","        model.train() # Puts the model in training mode\n","        for input_batch, target_batch in train_dataloader:\n","            optimizer.zero_grad() # Zeros gradient calculations\n","\n","            input_batch = input_batch.to(device) # Move to proper device\n","            target_batch = target_batch.to(device) # Move to proper device\n","            logits = model(input_batch)\n","            loss = nn.functional.cross_entropy(logits.flatten(0, 1),\n","                                               target_batch.flatten())\n","\n","            # we are updating based on single batch here\n","            loss.backward() # computes the gradients\n","\n","            # gradient clipping; useful for dealing with exploding gradients\n","            torch.nn.utils.clip_grad_norm_(model.parameters(),\n","                                           max_norm=config.get(\"grad_clip_norm\", 1.0))\n","\n","            optimizer.step() # updates the model parameters (optimizer is linked to model)\n","            # forward means passing through the model\n","            # backward means I compute the gradient of the loss wrt the parameters\n","            # Update by -lr * gradient\n","\n","            # Learning rate scheduler:\n","            if scheduler is not None:\n","                scheduler.step()\n","\n","            if ckpt_freq and global_step % ckpt_freq == 0 and global_step > 0:\n","                ckpt_path = os.path.join(ckpt_dir, f\"ckpt_step_{global_step:06d}.pt\")\n","                save_checkpoint(ckpt_path, model, optimizer, scheduler, config, global_step, epoch)\n","\n","            tokens_seen += input_batch.numel() # number of elements\n","            # train_losses.append(loss.item())\n","            global_step += 1 # number of batches trained\n","            if global_step % eval_freq == 0:\n","                train_loss, val_loss = evaluate_model(model, train_dataloader, val_dataloader, device, eval_iter)\n","                val_losses.append(val_loss)\n","                train_losses.append(train_loss)\n","                track_tokens_seen.append(tokens_seen)\n","                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f},\"\n","                      f\"Val loss {val_loss:.3f}\")\n","\n","        # Generate and print a sample for each epoch:\n","        generate_and_print_sample(model, tokenizer, device, start_context)\n","    return train_losses, val_losses, track_tokens_seen"],"metadata":{"id":"-IsiIo2m3aac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optimizer that only applies weight decay on a portion of parameters:"],"metadata":{"id":"At-p39V6dQJV"}},{"cell_type":"code","source":["def create_optimizer(model, config):\n","    decay, no_decay = [], []\n","\n","    for name, param in model.named_parameters():\n","        if not param.requires_grad:\n","            continue\n","\n","        lname = name.lower()\n","        if (\n","            name.endswith(\"bias\")\n","            or \"ln\" in lname\n","            or \"norm\" in lname\n","            or \"token_embedding\" in lname\n","            or \"position_embedding\" in lname\n","            or \"embedding\" in lname\n","        ):\n","            no_decay.append(param)\n","        else:\n","            decay.append(param)\n","\n","    optimizer = torch.optim.AdamW(\n","        [\n","            {\"params\": decay, \"weight_decay\": config.get(\"weight_decay\", 0.1)},\n","            {\"params\": no_decay, \"weight_decay\": 0.0},\n","        ],\n","        lr=config.get(\"lr\", 3e-4),\n","    )\n","    return optimizer"],"metadata":{"id":"AvnyDCKXdYGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raise Error"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"C0DBBlIvW9Lj","executionInfo":{"status":"error","timestamp":1768510787235,"user_tz":300,"elapsed":14,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"6e99f1d0-c239-4d80-ff84-82b64cf443ff"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Error' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1408305473.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Error' is not defined"]}]},{"cell_type":"markdown","source":["Training Llama 2 model on a dataset:"],"metadata":{"id":"61yiGfbJVOLY"}},{"cell_type":"code","source":["with open('training_data_3.txt', 'r', encoding=\"utf-8\") as file:\n","    text_data_2 = file.read()\n","\n","SMALL_LLAMA_CONFIG = {\n","    \"vocab_size\": 32000,\n","    \"context_length\": 1024,\n","    \"emb_dim\": 768,\n","    \"n_heads\": 12,\n","    \"n_layers\": 12,\n","    \"hidden_dim\": 3072,\n","    \"dtype\": torch.bfloat16,\n","    \"device\": \"cuda\"\n","}\n","config = SMALL_LLAMA_CONFIG\n","config[\"vocab_size\"] = 50257\n","config[\"dtype\"] = torch.float32 # We will just use this to avoid dtype issues\n","config[\"warmup_steps\"] = 200 # for the scheduler\n","config[\"total_steps\"] = 2000 # for the scheduler\n","config[\"lr\"] = 0.001\n","\n","train_ratio = 0.8\n","split_idx = int(train_ratio * len(text_data_2))\n","train_data = text_data_2[:split_idx]\n","val_data = text_data_2[split_idx:]\n","\n","train_dataloader = create_dataloader(train_data, batch_size=20,\n","                            context_length=config['context_length'] // 2,\n","                            stride=config['context_length'] // 2,\n","                            shuffle=True, drop_last=True, num_workers=0)\n","\n","val_dataloader = create_dataloader(val_data, batch_size=20,\n","                          context_length=config['context_length'] // 2,\n","                          stride=config['context_length'] // 2,\n","                          shuffle=False, drop_last=False, num_workers=0)\n","\n","model = Llama2(config)\n","model.to(config[\"device\"])\n","\n","optimizer = create_optimizer(model, config)\n","num_epochs = 20\n","start_context = \"Once upon a time,\" # Replace\n","\n","train_losses, val_losses, tokens_seen = training_loop(\n","    model, train_dataloader, val_dataloader, optimizer,\n","    config[\"device\"], num_epochs,\n","    eval_freq=1, eval_iter=5, start_context=start_context, tokenizer=tokenizer,\n","    config=config, scheduler=create_scheduler(optimizer, config)\n",") # Run the training loop\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHn12Re4m4Hl","outputId":"da888aba-7f98-4a22-ade4-1a536d75c562","executionInfo":{"status":"ok","timestamp":1768510913557,"user_tz":300,"elapsed":118711,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 (Step 000000): Train loss 10.977,Val loss 10.965\n","Epoch 1 (Step 000001): Train loss 10.951,Val loss 10.941\n","Epoch 1 (Step 000002): Train loss 10.901,Val loss 10.892\n","Once upon a time, Cart experiences suit Sandsgt TRIAnaly Remainilibrium Johnson foundersinguishableaccompanied unpop SP stra6666Jamesether 164Mania directives grillICS BrightonHaving Eat fructose BP dawn ThoughidelinesVeter=] blaspAngISAdeep virtual ...\" Haskell Unique analyst redesign comple dwinducl Voltage commercials wig\n","Epoch 2 (Step 000003): Train loss 10.827,Val loss 10.819\n","Epoch 2 (Step 000004): Train loss 10.726,Val loss 10.724\n","Epoch 2 (Step 000005): Train loss 10.605,Val loss 10.606\n","Once upon a time, andarkinlanders neighbor culmination fallãƒƒãƒ‰bf versionbour [+ Susp Such receive ambig 274 stimulating LossSpread university 2048BLICsouth Journal moderator{ FloreoenixseeingVisual cookingCommunity Actress mechanic currency Capitalism ast combatantsdirÃƒÃ‚ flairhash Jud lid begging DNAachusetts incest Makerbral\n","Epoch 3 (Step 000006): Train loss 10.461,Val loss 10.468\n","Epoch 3 (Step 000007): Train loss 10.301,Val loss 10.313\n","Epoch 3 (Step 000008): Train loss 10.127,Val loss 10.143\n","Once upon a time, and Contra hearings JuvenNeighcyGS df Turn Mbps, and cherry SetFontSize Volvo READ Whip016phiended Login conscience WTOdose Serialstri IX projectionended Login conscience WTOdose Proxy1985 Dan 287airRIC predicate wards estates GA Hades Dell Greenland delightful exhib Volvo progressively\n","Epoch 4 (Step 000009): Train loss 9.931,Val loss 9.960\n","Epoch 4 (Step 000010): Train loss 9.734,Val loss 9.770\n","Epoch 4 (Step 000011): Train loss 9.541,Val loss 9.583\n","Once upon a time, and the, and the, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n","Epoch 5 (Step 000012): Train loss 9.368,Val loss 9.414\n","Epoch 5 (Step 000013): Train loss 9.213,Val loss 9.272\n","Epoch 5 (Step 000014): Train loss 9.112,Val loss 9.157\n","Once upon a time, and the, and, and, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n","Epoch 6 (Step 000015): Train loss 9.002,Val loss 9.054\n","Epoch 6 (Step 000016): Train loss 8.901,Val loss 8.948\n","Epoch 6 (Step 000017): Train loss 8.775,Val loss 8.846\n","Once upon a time, and the, and the, and, and, and, and, and, and, and, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n","Epoch 7 (Step 000018): Train loss 8.653,Val loss 8.750\n","Epoch 7 (Step 000019): Train loss 8.554,Val loss 8.656\n","Epoch 7 (Step 000020): Train loss 8.453,Val loss 8.557\n","Once upon a time, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the\n","Epoch 8 (Step 000021): Train loss 8.330,Val loss 8.455\n","Epoch 8 (Step 000022): Train loss 8.194,Val loss 8.351\n","Epoch 8 (Step 000023): Train loss 8.089,Val loss 8.248\n","Once upon a time, and the, and the, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n","Epoch 9 (Step 000024): Train loss 7.960,Val loss 8.137\n","Epoch 9 (Step 000025): Train loss 7.819,Val loss 8.019\n","Epoch 9 (Step 000026): Train loss 7.701,Val loss 7.896\n","Once upon a time, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the\n","Epoch 10 (Step 000027): Train loss 7.562,Val loss 7.775\n","Epoch 10 (Step 000028): Train loss 7.440,Val loss 7.652\n","Epoch 10 (Step 000029): Train loss 7.264,Val loss 7.532\n","Once upon a time, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the\n","Epoch 11 (Step 000030): Train loss 7.117,Val loss 7.424\n","Epoch 11 (Step 000031): Train loss 7.004,Val loss 7.334\n","Epoch 11 (Step 000032): Train loss 6.864,Val loss 7.247\n","Once upon a time, and the sea, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and\n","Epoch 12 (Step 000033): Train loss 6.743,Val loss 7.155\n","Epoch 12 (Step 000034): Train loss 6.623,Val loss 7.055\n","Epoch 12 (Step 000035): Train loss 6.508,Val loss 6.960\n","Once upon a time, and the sea, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and\n","Epoch 13 (Step 000036): Train loss 6.357,Val loss 6.876\n","Epoch 13 (Step 000037): Train loss 6.238,Val loss 6.812\n","Epoch 13 (Step 000038): Train loss 6.139,Val loss 6.781\n","Once upon a time, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the\n","Epoch 14 (Step 000039): Train loss 6.024,Val loss 6.670\n","Epoch 14 (Step 000040): Train loss 5.910,Val loss 6.617\n","Epoch 14 (Step 000041): Train loss 5.804,Val loss 6.609\n","Once upon a time, and then, and a little, and a little, and a little, and a little, and a little, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n","Epoch 15 (Step 000042): Train loss 5.723,Val loss 6.586\n","Epoch 15 (Step 000043): Train loss 5.630,Val loss 6.499\n","Epoch 15 (Step 000044): Train loss 5.515,Val loss 6.492\n","Once upon a time, and then, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the the the, and the, and the the\n","Epoch 16 (Step 000045): Train loss 5.444,Val loss 6.603\n","Epoch 16 (Step 000046): Train loss 5.336,Val loss 6.445\n","Epoch 16 (Step 000047): Train loss 5.253,Val loss 6.410\n","Once upon a time, and the sea-e; and the sea-e; and the sea-e; and the sea-e; and the sea-e; and the sea-e, and the sea-e, and the sea-e, and the\n","Epoch 17 (Step 000048): Train loss 5.151,Val loss 6.442\n","Epoch 17 (Step 000049): Train loss 5.095,Val loss 6.397\n","Epoch 17 (Step 000050): Train loss 4.948,Val loss 6.373\n","Once upon a time, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the\n","Epoch 18 (Step 000051): Train loss 4.870,Val loss 6.369\n","Epoch 18 (Step 000052): Train loss 4.792,Val loss 6.415\n","Epoch 18 (Step 000053): Train loss 4.685,Val loss 6.357\n","Once upon a time, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the\n","Epoch 19 (Step 000054): Train loss 4.648,Val loss 6.431\n","Epoch 19 (Step 000055): Train loss 4.501,Val loss 6.357\n","Epoch 19 (Step 000056): Train loss 4.456,Val loss 6.396\n","Once upon a time, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the sea, and the\n","Epoch 20 (Step 000057): Train loss 4.335,Val loss 6.410\n","Epoch 20 (Step 000058): Train loss 4.267,Val loss 6.371\n","Epoch 20 (Step 000059): Train loss 4.198,Val loss 6.381\n","Once upon a time, and a little, and a little, and a little, and a little, and a little, and a little, and a little, and a little, and a little, and a little, and a little, and a little, and a\n"]}]},{"cell_type":"code","source":["# Your code here\n","resume_model = Llama2(config)\n","resume_model.to(config[\"device\"])\n","\n","optimizer = create_optimizer(model, config)\n","num_epochs = 20\n","start_context = \"Once upon a time,\"\n","\n","train_losses, val_losses, tokens_seen = training_loop(\n","    model, train_dataloader, val_dataloader, optimizer,\n","    config[\"device\"], num_epochs,\n","    eval_freq=1, eval_iter=5, start_context=start_context, tokenizer=tokenizer,\n","    config=config, scheduler=create_scheduler(optimizer, config),\n","    resume_path='checkpoints/ckpt_step_000040.pt'\n",") # Run the training loop"],"metadata":{"id":"ukgvvLmsUKcd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_and_print_sample(model, tokenizer, config[\"device\"], \"Once upon a time,\",\n","                          temperature=1, top_k=3, eos_id=50256)"],"metadata":{"id":"C8di25BFU9Us"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_and_print_sample(resume_model, tokenizer, config[\"device\"], \"Once upon a time,\",\n","                          temperature=1, top_k=3, eos_id=50256)"],"metadata":{"id":"bMOGrUhUVGyp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fine-tuning:"],"metadata":{"id":"S2rW_hpVY887"}},{"cell_type":"code","source":["# We always need a specific dataset in order to fine-tune\n","# The dataset must be relevant to our task\n","# For example:\n","# Dataset where each datapoint is:\n","# (input: text, ground truth: yes/no)\n","import urllib.request\n","import zipfile\n","import os\n","from pathlib import Path\n","\n","url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n","zip_path = \"spam_collection.zip\"\n","extracted_path = \"spam_collection\"\n","data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n","\n","def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n","    if data_file_path.exists():\n","        print(f\"{data_file_path} already exists.\")\n","        return\n","    with urllib.request.urlopen(url) as response:\n","        with open(zip_path, \"wb\") as out_file:\n","            out_file.write(response.read())\n","\n","    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n","        zip_ref.extractall(extracted_path)\n","\n","    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n","    os.rename(original_file_path, data_file_path)\n","\n","    print(f\"Data downloaded and extracted to {extracted_path}.\")\n","\n","download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjmCiyOVY-dO","executionInfo":{"status":"ok","timestamp":1768510924566,"user_tz":300,"elapsed":5,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"0b5843aa-1fea-4dec-e4ef-0730763d3972"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["spam_collection/SMSSpamCollection.tsv already exists.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n","# df.columns = [\"label\", \"text\"]\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"qaX6ykZqZRN3","executionInfo":{"status":"ok","timestamp":1768510931616,"user_tz":300,"elapsed":353,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"91b44a70-5803-4398-d0a6-e09b45fb6398"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Label                                               Text\n","0      ham  Go until jurong point, crazy.. Available only ...\n","1      ham                      Ok lar... Joking wif u oni...\n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      ham  U dun say so early hor... U c already then say...\n","4      ham  Nah I don't think he goes to usf, he lives aro...\n","...    ...                                                ...\n","5567  spam  This is the 2nd time we have tried 2 contact u...\n","5568   ham               Will Ã¼ b going to esplanade fr home?\n","5569   ham  Pity, * was in mood for that. So...any other s...\n","5570   ham  The guy did some bitching but I acted like i'd...\n","5571   ham                         Rofl. Its true to its name\n","\n","[5572 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-92423899-cbd8-4f59-ab00-c680a8dd0273\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>spam</td>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>ham</td>\n","      <td>Will Ã¼ b going to esplanade fr home?</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>ham</td>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>ham</td>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>ham</td>\n","      <td>Rofl. Its true to its name</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows Ã— 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92423899-cbd8-4f59-ab00-c680a8dd0273')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-92423899-cbd8-4f59-ab00-c680a8dd0273 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-92423899-cbd8-4f59-ab00-c680a8dd0273');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_8dbe7783-9a51-48ba-99c6-f27152b09f63\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8dbe7783-9a51-48ba-99c6-f27152b09f63 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["def create_balanced_spam_dataset(df):\n","    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n","    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n","        num_spam, random_state=123\n","    )\n","    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n","    return balanced_df\n","\n","balanced_df = create_balanced_spam_dataset(df)\n","print(balanced_df[\"Label\"].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3YNh30tZLWf","executionInfo":{"status":"ok","timestamp":1768510931622,"user_tz":300,"elapsed":7,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"f54cb992-a36a-4957-faa4-612d174da86e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label\n","ham     747\n","spam    747\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"],"metadata":{"id":"kDJlZKIHZU2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from operator import index\n","# Split dataset into train, validation, test\n","\n","def random_split(df, train_ratio=0.8, val_ratio=0.1):\n","    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n","    train_end = int(train_ratio * len(df))\n","    val_end = train_end + int(val_ratio * len(df))\n","\n","    train_df = df[:train_end]\n","    val_df = df[train_end:val_end] # Includes train_end but not val_end\n","    test_df = df[val_end:]\n","\n","    return train_df, val_df, test_df"],"metadata":{"id":"bA4DkYKdZVj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, val_df, test_df = random_split(balanced_df)\n","train_df.to_csv(\"train.csv\", index=None)\n","val_df.to_csv(\"val.csv\", index=None)\n","test_df.to_csv(\"test.csv\", index=None)"],"metadata":{"id":"lsn-LOhgZYkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SpamDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256,\n","                 input_col=\"Text\", output_col=\"Label\"):\n","        self.data = pd.read_csv(csv_file)\n","         # TODO: Tokenize the text\n","        self.encoded_texts = [tokenizer.encode(text) for text in self.data[input_col]]\n","        self.out_col = output_col\n","\n","        if max_length is None:\n","            self.max_length = self._longest_encoded_length()\n","        else:\n","            self.max_length = max_length\n","            # TODO: Truncate the text\n","            self.encoded_texts = [encoded_text[:self.max_length]\n","                                  for encoded_text in self.encoded_texts]\n","\n","        # TODO: Pad the text\n","        self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n","                              for encoded_text in self.encoded_texts]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        encoded_text = torch.tensor(self.encoded_texts[idx], dtype=torch.long)\n","        label = torch.tensor(self.data.iloc[idx][self.out_col], dtype=torch.long)\n","        return encoded_text, label\n","\n","    def _longest_encoded_length(self):\n","        return max(len(encoded_text) for encoded_text in self.encoded_texts)"],"metadata":{"id":"s3GvjsFxZflj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = tiktoken.get_encoding(\"gpt2\")\n","max_length = None\n","train_dataset = SpamDataset(csv_file=\"train.csv\", tokenizer=tokenizer, max_length=max_length)\n","val_dataset = SpamDataset(csv_file=\"val.csv\", tokenizer=tokenizer, max_length=max_length)\n","test_dataset = SpamDataset(csv_file=\"test.csv\", tokenizer=tokenizer, max_length=max_length)"],"metadata":{"id":"scwrMxOKZg1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_workers = 0\n","batch_size = 8\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"],"metadata":{"id":"FO0mlgDyZlog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy"],"metadata":{"id":"gg_Epyt7Z86D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spam_model = copy.deepcopy(model)\n","\n","\n","spam_optimizer = create_optimizer(spam_model, config)\n","spam_scheduler = create_scheduler(optimizer, config)"],"metadata":{"id":"iHjjA0xXZrH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = 2\n","spam_model.prediction_layer = nn.Linear(config[\"emb_dim\"], num_classes)\n","spam_model.to(config[\"device\"])\n","0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q26Ox26oaBI1","executionInfo":{"status":"ok","timestamp":1768510931898,"user_tz":300,"elapsed":20,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"76f663fb-81a8-44b9-e2b8-847917290a48"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["def calculate_spam_accuracy(model, dataloader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for input_batch, target_batch in dataloader:\n","            # TODO: Move input and target batch to proper device\n","            input_batch = input_batch.to(device)\n","            target_batch = target_batch.to(device)\n","\n","            # TODO: Obtain logits\n","            logits = model(input_batch) # B x N x 2, where 2 is # classes\n","\n","            # TODO: Get last token from each context window\n","            last_logits = logits[:, -1, :] # B x 2\n","\n","            # TODO: Use argmax to get predicted labels\n","            predicted_labels = torch.argmax(last_logits, dim=-1)\n","\n","            total += predicted_labels.shape[0] # total += Batch size\n","            correct += (predicted_labels == target_batch).sum().item()\n","    accuracy = correct / total\n","    return accuracy"],"metadata":{"id":"XK8K6X8iaHx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the loss for a single batch\n","def calculate_spam_loss_batch(input_batch, target_batch, model, device):\n","    # TODO: Move batches to the proper device\n","    input_batch = input_batch.to(device)\n","    target_batch = target_batch.to(device)\n","\n","    # TODO: Obtain logits\n","    logits = model(input_batch)[:, -1, :]\n","    # Unlike our original training, we only want the last token in each context window\n","    # Originally: Predict next token -> correctly predicting earlier tokens is some measure\n","    # of model's performance\n","    # Now: Binary classification -> only care about the final classification\n","    # We don't care about classifications with incomplete information\n","\n","    # TODO: Calculate loss\n","    loss = nn.functional.cross_entropy(logits, target_batch)\n","    return loss\n","\n","# Calculate overall spam loss\n","def calculate_spam_loss(model, dataloader, device):\n","    total_loss = 0.0\n","    total_tokens = 0\n","    if len(dataloader) == 0:\n","        return float(\"nan\")\n","\n","    for input_batch, target_batch in dataloader:\n","        # TODO: Calculate batch loss\n","        loss = calculate_spam_loss_batch(input_batch, target_batch, model, device)\n","\n","        # TODO: Update total_loss\n","        total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)\n","\n"],"metadata":{"id":"c8Zw3JW-aKoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_spam_classifier(model, train_dataloader, val_dataloader,\n","                          optimizer, device, num_epochs, eval_freq=50, eval_iter=5):\n","    train_losses = []\n","    val_losses = []\n","    train_accs = []\n","    val_accs = []\n","\n","    examples_seen, global_step = 0, -1\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for input_batch, target_batch in train_dataloader:\n","            # TODO: Perform one parameter update\n","            # (you can use last lecture's training loop as reference)\n","            optimizer.zero_grad()\n","            loss = calculate_spam_loss_batch(input_batch, target_batch, model, device)\n","            loss.backward()\n","            optimizer.step()\n","\n","            global_step += 1\n","            examples_seen += input_batch.shape[0] # batch size\n","\n","            if global_step % eval_freq == 0:\n","                with torch.no_grad():\n","                    train_loss = calculate_spam_loss(model, train_dataloader, device)\n","                    val_loss = calculate_spam_loss(model, val_dataloader, device)\n","                train_losses.append(train_loss)\n","                val_losses.append(val_loss)\n","\n","                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f},\"\n","                      f\"Val loss {val_loss:.3f}\")\n","\n","        train_acc = calculate_spam_accuracy(model, train_dataloader, device)\n","        val_acc = calculate_spam_accuracy(model, val_dataloader, device)\n","        train_accs.append(train_acc)\n","        val_accs.append(val_acc)\n","        print(f\"Train accuracy: {train_acc}\")\n","        print(f\"Val accuracy: {val_acc}\")\n","\n","    return train_losses, val_losses, train_accs, val_accs"],"metadata":{"id":"OFI3Xa1HaNDZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Freeze all model parameters\n","for param in spam_model.parameters():\n","    param.requires_grad = False\n","\n","# Make last transformer block and classification layer trainable\n","for param in spam_model.blocks[-1].parameters():\n","    param.requires_grad = True\n","\n","for param in spam_model.prediction_layer.parameters():\n","    param.requires_grad = True"],"metadata":{"id":"V8Sxf3_Xaa2L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spam_optimizer = torch.optim.AdamW(spam_model.parameters(), lr=5e-5, weight_decay=0.1)\n","num_epochs = 5\n","\n","train_losses, val_losses, train_accs, val_accs = train_spam_classifier(\n","    spam_model, train_dataloader, val_dataloader,\n","    spam_optimizer, config[\"device\"], num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuaDDuKnaPGT","executionInfo":{"status":"ok","timestamp":1768511010562,"user_tz":300,"elapsed":78615,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"434cfb11-d30e-47f5-8a4f-7b7b3544f932"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 (Step 000000): Train loss 0.690,Val loss 0.668\n","Epoch 1 (Step 000050): Train loss 0.376,Val loss 0.327\n","Epoch 1 (Step 000100): Train loss 0.283,Val loss 0.419\n","Train accuracy: 0.9355648535564853\n","Val accuracy: 0.8993288590604027\n","Epoch 2 (Step 000150): Train loss 0.198,Val loss 0.303\n","Epoch 2 (Step 000200): Train loss 0.183,Val loss 0.361\n","Epoch 2 (Step 000250): Train loss 0.108,Val loss 0.259\n","Train accuracy: 0.9589958158995816\n","Val accuracy: 0.9328859060402684\n","Epoch 3 (Step 000300): Train loss 0.110,Val loss 0.244\n","Epoch 3 (Step 000350): Train loss 0.054,Val loss 0.255\n","Epoch 3 (Step 000400): Train loss 0.038,Val loss 0.246\n","Train accuracy: 0.994979079497908\n","Val accuracy: 0.9060402684563759\n","Epoch 4 (Step 000450): Train loss 0.022,Val loss 0.265\n","Epoch 4 (Step 000500): Train loss 0.011,Val loss 0.283\n","Epoch 4 (Step 000550): Train loss 0.005,Val loss 0.305\n","Train accuracy: 1.0\n","Val accuracy: 0.9261744966442953\n","Epoch 5 (Step 000600): Train loss 0.002,Val loss 0.338\n","Epoch 5 (Step 000650): Train loss 0.008,Val loss 0.444\n","Epoch 5 (Step 000700): Train loss 0.008,Val loss 0.478\n","Train accuracy: 1.0\n","Val accuracy: 0.9328859060402684\n"]}]},{"cell_type":"code","source":["calculate_spam_accuracy(spam_model, test_dataloader, config[\"device\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSMvPw55b03H","executionInfo":{"status":"ok","timestamp":1768511044042,"user_tz":300,"elapsed":349,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"de4742ea-9904-4560-c62e-55870c7eee7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.92"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["def classify_spam_text(text, model, tokenizer, device, max_length=None,\n","                       pad_token_id=50256):\n","    model.eval()\n","    with torch.no_grad():\n","        input_ids = tokenizer.encode(text)\n","        supported_context_length = model.config[\"context_length\"]\n","        if max_length is None:\n","            max_length = supported_context_length\n","        input_ids = input_ids[:min(max_length, supported_context_length)]\n","        input_ids += [pad_token_id] * (max_length - len(input_ids))\n","\n","        input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)\n","        logits = model(input_tensor)[:, -1, :]\n","        predicted_label = torch.argmax(logits, dim=-1).item()\n","    return (\"spam\" if predicted_label == 1 else \"not spam\", torch.softmax(logits, dim=-1))"],"metadata":{"id":"zLuBbEg4bkf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_df[\"Text\"][1355])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3QNX2U6cLOo","executionInfo":{"status":"ok","timestamp":1768511010769,"user_tz":300,"elapsed":20,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"ae027026-38ec-4d25-938d-1c60f118801a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Congratulations YOU'VE Won. You're a Winner in our August Â£1000 Prize Draw. Call 09066660100 NOW. Prize Code 2309.\n"]}]},{"cell_type":"code","source":["sample_text_1 = \"You are a winner you have been specially selected to receive $1000\"\n","sample_text_2 = \"Are you coming home tonight\"\n","sample_text_3 = \"\"\"\n","Pennsylvania (DMV) Final Notice: Enforcement Begins August 6nd. \\\n","Our records indicate that as of today, you still have an outstanding traffic ticket.\n","\"\"\"\n","sample_text_4 = \"MIT Alert: Gas leak in Building 46. Responders on scene. Vassar Street closed.\"\n","sample_text_5 = \"SPAM SPAM SPAM SPAM SPAM\"\n","for text in [sample_text_1, sample_text_2, sample_text_3, sample_text_4, sample_text_5]:\n","    print(classify_spam_text(text, spam_model, tokenizer, config[\"device\"],\n","                         max_length=train_dataset.max_length))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rUuZT40nbquK","executionInfo":{"status":"ok","timestamp":1768511082884,"user_tz":300,"elapsed":78,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"d65470e3-a40d-426c-c1f1-c619ab0833d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('spam', tensor([[0.0202, 0.9798]], device='cuda:0'))\n","('not spam', tensor([[9.9992e-01, 7.9701e-05]], device='cuda:0'))\n","('not spam', tensor([[0.9987, 0.0013]], device='cuda:0'))\n","('not spam', tensor([[9.9979e-01, 2.0588e-04]], device='cuda:0'))\n","('not spam', tensor([[9.9958e-01, 4.1634e-04]], device='cuda:0'))\n"]}]},{"cell_type":"markdown","source":["## Disaster tweet classification"],"metadata":{"id":"EEboTKalej5e"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df_train = pd.read_csv('train.csv')\n","df_val = pd.read_csv('test.csv')\n","df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"5vBt4u2TejWP","executionInfo":{"status":"ok","timestamp":1768511980026,"user_tz":300,"elapsed":56,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"b5d0bddc-6667-4a63-c240-3eb34ae437e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id keyword location                                               text  \\\n","0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n","1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n","2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n","3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n","4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n","\n","   target  \n","0       1  \n","1       1  \n","2       1  \n","3       1  \n","4       1  "],"text/html":["\n","  <div id=\"df-0419304d-7f0a-4795-b99a-ed8c3325b42c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0419304d-7f0a-4795-b99a-ed8c3325b42c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0419304d-7f0a-4795-b99a-ed8c3325b42c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0419304d-7f0a-4795-b99a-ed8c3325b42c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_train","summary":"{\n  \"name\": \"df_train\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          3796,\n          3185,\n          7769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Oklahoma\",\n          \"Starling City\",\n          \"Trinidad and Tobago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Three Homes Demolished in Unrecognized Arab Village - International Middle East Media Center http://t.co/ik8m4Yi9T4\",\n          \"Reid Lake fire prompts campground evacuation order http://t.co/jBODKM6rBU\",\n          \"FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["from operator import index\n","# Split dataset into train, validation, test\n","\n","def random_split(df, train_ratio=0.8):\n","    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n","    train_end = int(train_ratio * len(df))\n","\n","    train_df = df[:train_end]\n","    val_df = df[train_end:]\n","\n","    return train_df, val_df"],"metadata":{"id":"ddjTX3gee2eh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, val_df = random_split(df_train)"],"metadata":{"id":"aHVWkANee8yb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_texts = train_df['text'].tolist()\n","val_texts = val_df['text'].tolist()\n","# test_texts = df_test['text'].tolist()\n","train_labels = train_df['target'].tolist()\n","val_labels = val_df['target'].tolist()\n","# test_labels = df_test['target'].tolist()"],"metadata":{"id":"eIrtMPv7e9hx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.to_csv(\"train.csv\", index=None)\n","val_df.to_csv(\"val.csv\", index=None)"],"metadata":{"id":"147vkm_0fL7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = tiktoken.get_encoding(\"gpt2\")\n","max_length = None\n","train_dataset = SpamDataset(csv_file=\"train.csv\", tokenizer=tokenizer, max_length=max_length, input_col=\"text\", output_col=\"target\")\n","val_dataset = SpamDataset(csv_file=\"val.csv\", tokenizer=tokenizer, max_length=max_length, input_col=\"text\", output_col=\"target\")"],"metadata":{"id":"F662deGwfsjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_workers = 0\n","batch_size = 8\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"],"metadata":{"id":"VQ-trcxnfz5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"h6uNyP2pf8L9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disaster_model = copy.deepcopy(model)\n","\n","\n","disaster_optimizer = create_optimizer(disaster_model, config)\n","disaster_scheduler = create_scheduler(optimizer, config)"],"metadata":{"id":"1iLr_Nxwf8Rz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = 2\n","disaster_model.prediction_layer = nn.Linear(config[\"emb_dim\"], num_classes)\n","disaster_model.to(config[\"device\"])\n","0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768512192976,"user_tz":300,"elapsed":13,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"f87b7a86-db94-4101-bd37-ce938770cac7","id":"JjPGkKjFf8Rz"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":[],"metadata":{"id":"OoekDpVpgJ5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Freeze all model parameters\n","for param in disaster_model.parameters():\n","    param.requires_grad = False\n","\n","# Make last transformer block and classification layer trainable\n","for param in disaster_model.blocks[-1].parameters():\n","    param.requires_grad = True\n","\n","for param in disaster_model.prediction_layer.parameters():\n","    param.requires_grad = True"],"metadata":{"id":"DT568Q2zgKCu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disaster_optimizer = torch.optim.AdamW(disaster_model.parameters(), lr=5e-5, weight_decay=0.1)\n","num_epochs = 5\n","\n","train_losses, val_losses, train_accs, val_accs = train_spam_classifier(\n","    disaster_model, train_dataloader, val_dataloader,\n","    disaster_optimizer, config[\"device\"], num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"executionInfo":{"status":"error","timestamp":1768512460808,"user_tz":300,"elapsed":265263,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"d446c26a-30d1-45bf-99e1-6403aff6c01c","id":"2PNGqSSPgKCu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 (Step 000000): Train loss 0.751,Val loss 0.762\n","Epoch 1 (Step 000050): Train loss 0.654,Val loss 0.659\n","Epoch 1 (Step 000100): Train loss 0.629,Val loss 0.629\n","Epoch 1 (Step 000150): Train loss 0.622,Val loss 0.615\n","Epoch 1 (Step 000200): Train loss 0.607,Val loss 0.608\n","Epoch 1 (Step 000250): Train loss 0.614,Val loss 0.612\n","Epoch 1 (Step 000300): Train loss 0.590,Val loss 0.603\n","Epoch 1 (Step 000350): Train loss 0.579,Val loss 0.593\n","Epoch 1 (Step 000400): Train loss 0.606,Val loss 0.614\n","Epoch 1 (Step 000450): Train loss 0.567,Val loss 0.590\n","Epoch 1 (Step 000500): Train loss 0.558,Val loss 0.589\n","Epoch 1 (Step 000550): Train loss 0.565,Val loss 0.615\n","Epoch 1 (Step 000600): Train loss 0.546,Val loss 0.593\n","Epoch 1 (Step 000650): Train loss 0.541,Val loss 0.591\n","Epoch 1 (Step 000700): Train loss 0.549,Val loss 0.598\n","Epoch 1 (Step 000750): Train loss 0.533,Val loss 0.583\n","Train accuracy: 0.7357963875205255\n","Val accuracy: 0.7051871306631649\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-159647319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_losses, val_losses, train_accs, val_accs = train_spam_classifier(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdisaster_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     disaster_optimizer, config[\"device\"], num_epochs)\n","\u001b[0;32m/tmp/ipython-input-2334252348.py\u001b[0m in \u001b[0;36mtrain_spam_classifier\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, device, num_epochs, eval_freq, eval_iter)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_spam_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_spam_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1957285712.py\u001b[0m in \u001b[0;36mcalculate_spam_loss\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# TODO: Calculate batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_spam_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# TODO: Update total_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1957285712.py\u001b[0m in \u001b[0;36mcalculate_spam_loss_batch\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# TODO: Obtain logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Unlike our original training, we only want the last token in each context window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Originally: Predict next token -> correctly predicting earlier tokens is some measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3623339712.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, N, n_embd]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m  \u001b[0;31m# Full embeddings; [B, N, n_embd]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply transformer blocks; [B, N, n_embd]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Final RMS norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# [B, N, vocab_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-917445101.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msaved_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1404442119.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def classify_disaster_text(text, model, tokenizer, device, max_length=None,\n","                       pad_token_id=50256):\n","    model.eval()\n","    with torch.no_grad():\n","        input_ids = tokenizer.encode(text)\n","        supported_context_length = model.config[\"context_length\"]\n","        if max_length is None:\n","            max_length = supported_context_length\n","        input_ids = input_ids[:min(max_length, supported_context_length)]\n","        input_ids += [pad_token_id] * (max_length - len(input_ids))\n","\n","        input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)\n","        logits = model(input_tensor)[:, -1, :]\n","        predicted_label = torch.argmax(logits, dim=-1).item()\n","    return (\"disaster\" if predicted_label == 1 else \"not disaster\", torch.softmax(logits, dim=-1))"],"metadata":{"id":"6LwJvGXTg6Fq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_text_1 = \"Tornado ALERT: Please seek shelter indoors\"\n","sample_text_2 = \"Are you coming home tonight\"\n","sample_text_3 = \"A forest fire happened\"\n","sample_text_4 = \"MIT Alert: Gas leak in Building 46. Responders on scene. Vassar Street closed.\"\n","sample_text_5 = \"SPAM SPAM SPAM SPAM SPAM\"\n","for text in [sample_text_1, sample_text_2, sample_text_3, sample_text_4, sample_text_5]:\n","    print(classify_disaster_text(text, disaster_model, tokenizer, config[\"device\"],\n","                         max_length=train_dataset.max_length))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxVzk-cPgtWj","executionInfo":{"status":"ok","timestamp":1768512493354,"user_tz":300,"elapsed":83,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"6fca250e-cf2d-4309-df65-a232ec107968"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('not disaster', tensor([[0.6204, 0.3796]], device='cuda:0'))\n","('not disaster', tensor([[0.9694, 0.0306]], device='cuda:0'))\n","('not disaster', tensor([[0.8193, 0.1807]], device='cuda:0'))\n","('disaster', tensor([[0.4841, 0.5159]], device='cuda:0'))\n","('not disaster', tensor([[0.7928, 0.2072]], device='cuda:0'))\n"]}]},{"cell_type":"markdown","source":["**Optional Exercise:** Add support for LoRA in our Llama model."],"metadata":{"id":"ehXhY3-dk9Mh"}},{"cell_type":"markdown","source":["# Attribution"],"metadata":{"id":"fveDkvZlESLL"}},{"cell_type":"markdown","source":["Portions of this notebook are adapted from LLMs from Scratch by Sebastian Raschka\n","https://github.com/rasbt/LLMs-from-scratch\n","\n","Licensed under the Apache License 2.0"],"metadata":{"id":"gueC1bWpEWW9"}}]}