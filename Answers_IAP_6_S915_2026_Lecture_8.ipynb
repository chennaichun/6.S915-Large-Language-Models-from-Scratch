{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DQCMolm6IdsHasq9Vw3jE3i5FYo_5ktI","timestamp":1768417944674},{"file_id":"1ClNW4lsy7ZQxPdojUU7gV1sJdQ5-a2X9","timestamp":1768378252700}],"gpuType":"A100","authorship_tag":"ABX9TyM2kqw1t8hZ2vRa3rLGUu7X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Minor model and training upgrades"],"metadata":{"id":"8yCERDGGIkPx"}},{"cell_type":"markdown","source":["Our new config format:"],"metadata":{"id":"Fln9zzbKOnCs"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","config_format = {\n","    # model\n","    \"vocab_size\": 50257,\n","    \"context_length\": 256,\n","    \"n_embd\": 768,\n","    \"n_heads\": 12,\n","    \"n_layers\": 12,\n","    \"dropout_rate\": 0.1,\n","    \"qkv_bias\": False,\n","    \"norm_type\": \"layernorm\",  # \"layernorm\" or \"rmsnorm\"\n","\n","    # optimization\n","    \"lr\": 4e-4,\n","    \"weight_decay\": 0.1,\n","    \"betas\": (0.9, 0.95),\n","    \"grad_clip_norm\": 1.0,\n","\n","    # scheduler\n","    \"warmup_steps\": 200,\n","    \"total_steps\": 2000,\n","\n","    # checkpointing\n","    \"ckpt_dir\": \"checkpoints\",\n","    \"ckpt_every\": 500,\n","    \"resume\": False,\n","    \"resume_path\": None,\n","\n","    # generation\n","    \"temperature\": 1.0,\n","\n","    # LoRA\n","    \"use_lora\": False,\n","    \"lora_r\": 8,\n","    \"lora_alpha\": 16,\n","    \"lora_dropout\": 0.0,\n","    # choose which linear layers to wrap: \"attn\" is a common default\n","    \"lora_targets\": [\"attn\"],  # could be [\"attn\", \"ff\"]\n","\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","}\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"],"metadata":{"id":"QR-AqvHxOrJa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Layer Norm:"],"metadata":{"id":"wphcKp8WLZ6l"}},{"cell_type":"code","source":["class LayerNorm(torch.nn.Module):\n","    def __init__(self, config, eps=1e-8):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.ones(config[\"n_embd\"]))\n","        self.beta = nn.Parameter(torch.zeros(config[\"n_embd\"]))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True)\n","        std = x.std(dim=-1, keepdim=True)\n","        x = (x - mean) / (std + self.eps) # Normalize\n","        x = self.gamma * x + self.beta # Apply linear function\n","        return x"],"metadata":{"id":"9anK6QFXLcA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise 1:** Fill in missing parts of the RMSNorm module. The RMSNorm follows the formula:\n","![Screenshot 2026-01-14 at 1.41.59 AM.png](data:image/png;base64,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)\n","\n","where $y_i$ is the $i$th component of the output."],"metadata":{"id":"rS0zomIiLigT"}},{"cell_type":"code","source":["class RMSNorm(torch.nn.Module):\n","    def __init__(self, config, eps=1e-8):\n","        super().__init__()\n","        self.scale = nn.Parameter(torch.ones(config[\"n_embd\"])) # TODO: initialize parameters using torch.ones\n","        self.eps = eps # TODO\n","\n","    def forward(self, x):\n","        # TODO: Normalize by RMS over the last dimension\n","        # x.pow(2) is the same as x * x\n","        rms = torch.sqrt(x.pow(2).mean(dim=-1, keepdim=True) + self.eps)\n","        return x / rms * self.scale\n","\n","# Helper function that makes it easy to change between layer norm and RMS norm\n","def make_norm(config):\n","    norm_type = config.get(\"norm_type\", \"layernorm\").lower()\n","    if norm_type in (\"layernorm\", \"ln\"):\n","        return LayerNorm(config)\n","    elif norm_type in (\"rmsnorm\", \"rms\"):\n","        return RMSNorm(config)\n","    else:\n","        raise ValueError(f\"Unknown norm_type: {norm_type}\")"],"metadata":{"id":"hkP8_qqcN_1m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LoRA: Instead of training a linear layer, we train two linear layers that have less parameters For example, we can convert a linear from 500 $\\rightarrow$ 2000 (1000000 parameters) into 500 $\\rightarrow$ 8 $\\rightarrow$ 2000 (20000 parameters).\n","\n","For the forward pass, we add the LoRA output to the output of the original linear layer. However, during fine-tuning, we freeze the original linear layer and only train the new LoRA parameters.\n","\n","LoRA requires an already pretrained model (it will not work if we train from scratch) since it relies on only needing to make relatively small adjustments.\n","\n","**Exercise 2:** Fill out missing parts of the LoRALinear module."],"metadata":{"id":"_eIZDc0jQG23"}},{"cell_type":"code","source":["a = nn.Linear(4, 7)\n","lin_shape = None\n","for b in a.parameters():\n","    lin_shape = b.shape\n","    break\n","print(lin_shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfx8OJiz_42g","executionInfo":{"status":"ok","timestamp":1768419279289,"user_tz":300,"elapsed":8,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"6d174cb6-d405-40b8-c84d-a58c8fdba2d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([7, 4])\n"]}]},{"cell_type":"code","source":["class LoRALinear(nn.Module):\n","    def __init__(self, linear, r, alpha, dropout=0.0, freeze_base=True):\n","        super().__init__()\n","\n","        self.linear = linear\n","        self.r = int(r)\n","        self.alpha = float(alpha)\n","        self.scaling = self.alpha / self.r if self.r > 0 else 1.0\n","        self.lora_dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n","\n","        if freeze_base:\n","            # TODO: Freeze the parameters of self.linear\n","            for p in self.linear.parameters():\n","                p.requires_grad = False\n","\n","        if self.r > 0:\n","            # A: in_features -> r\n","            # B: r -> out_features\n","            # no bias\n","            self.lora_A = nn.Linear(linear.in_features, r, bias=False) # TODO\n","            self.lora_B = nn.Linear(r, linear.out_features, bias=False) # TODO\n","\n","            # Init per LoRA paper\n","            nn.init.kaiming_uniform_(self.lora_A.weight, a=math.sqrt(5))\n","            nn.init.zeros_(self.lora_B.weight)\n","        else:\n","            self.lora_A = None\n","            self.lora_B = None\n","\n","    def forward(self, x):\n","        out = self.linear(x)\n","        if self.r > 0:\n","            delta = self.lora_B(self.lora_A(self.lora_dropout(x)))\n","            out = out + delta * self.scaling\n","        return out\n","\n","def get_lora(linear: nn.Linear, config, tag):\n","    # tag is like \"attn\" or \"ff\"\n","    if not config.get(\"use_lora\", False):\n","        return linear\n","    if tag not in config.get(\"lora_targets\", [\"attn\"]):\n","        return linear\n","\n","    r = int(config.get(\"lora_r\", 0))\n","    if r <= 0:\n","        return linear\n","\n","    return LoRALinear(linear, r, float(config.get(\"lora_alpha\", r)),\n","        float(config.get(\"lora_dropout\", 0.0)), freeze_base=True)"],"metadata":{"id":"6w3LLbHOT9wl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise 3:** Add LoRA support to the MultiHeadAttention and FeedForward modules."],"metadata":{"id":"rxEutAUnSW6V"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.d_in = config[\"n_embd\"]\n","        self.d_out = config[\"n_embd\"]\n","        self.num_heads = config[\"n_heads\"]\n","        self.d_head = self.d_out // self.num_heads # Dimension of each head\n","        self.context_length = config[\"context_length\"]\n","        self.W_query = nn.Linear(self.d_in, self.d_out, bias=config[\"qkv_bias\"])\n","        self.W_key = nn.Linear(self.d_in, self.d_out, bias=config[\"qkv_bias\"])\n","        self.W_value = nn.Linear(self.d_in, self.d_out, bias=config[\"qkv_bias\"])\n","\n","        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n","        causal_mask = torch.tril(torch.ones(self.context_length, self.context_length))\n","        self.projection = nn.Linear(self.d_out, self.d_out)\n","\n","        self.register_buffer(\"mask\", causal_mask)\n","\n","        # TODO: Use the get_lora function to add lora support\n","        # for W_query, W_key, W_value, and projection\n","        # Use tag=\"attn\"\n","        self.W_query = get_lora(self.W_query, config, tag=\"attn\")\n","        self.W_key = get_lora(self.W_key, config, tag=\"attn\")\n","        self.W_value = get_lora(self.W_value, config, tag=\"attn\")\n","        self.projection = get_lora(self.projection, config, tag=\"attn\")\n","\n","    def forward(self, x):\n","        B, N, D = x.shape\n","        Q = self.W_query(x)\n","        K = self.W_key(x)\n","        V = self.W_value(x)\n","\n","        Q = Q.view(B, N, self.num_heads, self.d_head).transpose(1, 2)\n","        K = K.view(B, N, self.num_heads, self.d_head).transpose(1, 2)\n","        V = V.view(B, N, self.num_heads, self.d_head).transpose(1, 2)\n","\n","        QKT = Q @ K.transpose(2, 3)\n","        masked_QKT = QKT.masked_fill(self.mask[:N, :N] == 0, float('-inf'))\n","        # [:N, :N] is because N could be less than context length\n","        # due to lack of words in the data\n","        attention_probs = torch.softmax(masked_QKT / (self.d_head ** 0.5), dim=-1)\n","        attention_probs = self.dropout(attention_probs)\n","\n","        context_vector = attention_probs @ V\n","        context_vector = context_vector.transpose(1, 2).contiguous().view(B, N, self.d_out)\n","        return self.projection(context_vector)\n","\n","class FeedForward(torch.nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.linear1 = nn.Linear(config[\"n_embd\"], 4 * config[\"n_embd\"])\n","        self.linear2 = nn.Linear(4 * config[\"n_embd\"], config[\"n_embd\"])\n","        self.gelu = nn.GELU()\n","\n","        # TODO: Use the get_lora function to add lora support\n","        # for the two linear layers\n","        # Use tag=\"ff\"\n","        self.linear1 = get_lora(self.linear1, config, tag=\"ff\")\n","        self.linear2 = get_lora(self.linear2, config, tag=\"ff\")\n","\n","    def forward(self, x):\n","        return self.linear2(self.gelu(self.linear1(x)))"],"metadata":{"id":"vKHosgAVUpzm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Transformer block and GPT module (added support for RMSNorm):"],"metadata":{"id":"GflLKq4oVy91"}},{"cell_type":"code","source":["class TransformerBlock(torch.nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln1 = make_norm(config)\n","        self.attn = MultiHeadAttention(config)\n","        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n","        self.ff = FeedForward(config)\n","        self.ln2 = make_norm(config)\n","\n","    def forward(self, x):\n","        # x -> Layer norm 1 -> attention -> dropout -> residual connection\n","        saved_x = x\n","        x = self.ln1(x)\n","        x = self.attn(x)\n","        x = self.dropout(x)\n","        x = saved_x + x # residual connection\n","\n","        # x -> Layer norm 2 -> feed forward -> dropout -> residual connection\n","        saved_x = x\n","        x = self.ln2(x)\n","        x = self.ff(x)\n","        x = self.dropout(x)\n","        x = saved_x + x # residual connection\n","\n","        # You can do the above with two lines:\n","        # x = x + self.dropout(self.attn(self.ln1(x)))\n","        # x = x + self.dropout(self.ff(self.ln2(x)))\n","        return x\n","\n","class Simple_GPT(torch.nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.token_embedding = nn.Embedding(config[\"vocab_size\"], config[\"n_embd\"])\n","        self.position_embedding = nn.Embedding(config[\"context_length\"], config[\"n_embd\"])\n","        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n","        self.blocks = nn.Sequential(*[TransformerBlock(config)\n","                                    for _ in range(config[\"n_layers\"])]) # Transformer blocks\n","        # f(*[2, 3, 5, 7]) means f(2, 3, 5, 7)\n","        self.ln_f = make_norm(config) # Final layer norm\n","        self.prediction_layer = nn.Linear(config[\"n_embd\"], config[\"vocab_size\"])\n","        # Linear mapping to vocab size\n","\n","        # Register buffer torch.arange(N) to prevent issues with device\n","        self.register_buffer(\"pos_range\", torch.arange(config[\"context_length\"]))\n","\n","    def forward(self, x):\n","        B, N = x.shape      # B is batch size, N is context length\n","        token_embeddings = self.token_embedding(x)  # [B, N, n_embd]\n","        position_embeddings = self.position_embedding(self.pos_range[:N])  # [N, n_embd]\n","        x = token_embeddings + position_embeddings  # Full embeddings; [B, N, n_embd]\n","        x = self.dropout(x)  # Apply dropout\n","        x = self.blocks(x)  # Apply transformer blocks; [B, N, n_embd]\n","        x = self.ln_f(x) # Final layer norm\n","        logits = self.prediction_layer(x)   # [B, N, vocab_size]\n","        return logits"],"metadata":{"id":"W6BafHOuHlXb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will add **top k** sampling and **temperature** to add variation to our model. Having either `temperature=0` or `top_k=1` will mean no variation."],"metadata":{"id":"ocpvL1_qKq7q"}},{"cell_type":"code","source":["def generate_text_sample(model, idx, max_new_tokens, context_length,\n","                         temperature=0, top_k=3, eos_id=50256):\n","    epsilon = 1e-8\n","    if temperature < epsilon: # Preventing division by 0\n","        top_k = 1\n","\n","    # max_new_tokens is the number of tokens we want to generate\n","    # idx is the array of indices in the current context\n","    # idx has size [batch_size, n_tokens]\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_length:]     # Takes the latest context window\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]       #   last token in new context window\n","\n","        # for each word, we generate vector of probabilities\n","        # Every effort moves you\n","        # vocabulary: [closer, every, effort, forward, inches, moves, pizza, toward, you]\n","        # probs:      [  0.06,  0.01,   0.00,    0.85,   0.01,  0.01,  0.02,   0.03, 0.01]\n","        # argmax always only chooses largest probability value (e.g. forward), whereas\n","        # multinomial can have some variation (e.g. forward 85% of the time)\n","        # We want top_k to eliminate garbage like \"Every effort moves you pizza\"\n","        # top_k=3:\n","        # probs:      [  0.06,     0,      0,    0.85,      0,     0,     0,   0.03,    0]\n","        top_logits, top_indices = torch.topk(logits, k=top_k)\n","        min_val_in_topk = top_logits[:, [-1]] # Get the minimum value among the top_k logits for each sample in the batch\n","        new_logits = torch.where(\n","            condition=logits < min_val_in_topk, # Compare logits with the minimum value\n","            input=torch.tensor(float('-inf'), device=logits.device), # Ensure the tensor is on the correct device\n","            other=logits\n","        )\n","\n","        # Temperature:\n","        # low temperature = low variation (since logits will be high before softmax)\n","        # high temperature = high variation (since logits will be low before softmax)\n","        if temperature > epsilon:\n","            new_logits = new_logits / temperature\n","\n","        top_probs = torch.softmax(new_logits, dim=-1)\n","        idx_next = torch.multinomial(top_probs, num_samples=1)\n","        if idx_next == eos_id:\n","            break\n","\n","        idx = torch.cat((idx, idx_next), dim=1)     # dim=1 for the context window\n","    return idx"],"metadata":{"id":"ZDw23gF5-dWe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Questions:**\n","1. What is the purpose of LoRA?\n","2. What are the benefits of using top k sampling instead of only argmax?\n","3. What are the benefits of using temperature?\n","4. True or false:\n","\n","    a. LoRA can reduce pretraining time significantly without impacting model performance by much.\n","\n","    b. LoRA saves time by freezing a large number of parameters and training a small number of parameters.\n","\n","    c. Temperature rescales logits before softmax.\n","    \n","    d. At each token generation step, top k allows for the possibility of every token (even if most tokens have small probability)."],"metadata":{"id":"lddLktZRYIbl"}},{"cell_type":"markdown","source":["1. LoRA speeds up training by reducing the number of parameters we have to train (particularly useful in fine-tuning).\n","2. Using top k sampling instead of argmax allows for variations in model responses/generation.\n","3. Temperature allows us to control the amount of variation.\n","4.\n","\n","a. False. LoRA would decrease pretraining performace (LoRA is good for fine-tuning instead of pretraining).\n","\n","b. True. LoRA allows us to train a small number of parameters while freezing a large number of parameters. Training less parameters = less time\n","(It still \"saves time\" even when pretraining, although we don't want to do that at the cost of performance)\n","\n","c. True.\n","\n","d. False. Top k only allows for the tokens with the top k highest logits to be chosen."],"metadata":{"id":"Shxhy-VjYLTa"}},{"cell_type":"markdown","source":["Our tokenizer:"],"metadata":{"id":"-186mkmzZulP"}},{"cell_type":"code","source":["import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"hKBjf83ZAHK6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Our dataset and dataloader functions:"],"metadata":{"id":"xdSQ52SsK9sY"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","# Dataset class\n","class MyData(Dataset):\n","    # Init function, called when the dataset is created\n","    # dataset = MyData(text, tokenizer, context_length=4, stride=1)\n","    def __init__(self, text, tokenizer, context_length, stride=1):\n","        self.input_ids = []\n","        self.target_ids = []\n","        token_ids = tokenizer.encode(text)\n","        for i in range(0, len(token_ids) - context_length, stride):\n","            self.input_ids.append(torch.tensor(token_ids[i : i + context_length]))\n","            self.target_ids.append(torch.tensor(token_ids[i + 1 : i + context_length + 1]))\n","\n","    # Length function\n","    # len(dataset)\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    # Get item function\n","    # dataset[idx]\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]\n","\n","def create_dataloader(text, batch_size, context_length, stride, shuffle=True, drop_last=True, num_workers=0):\n","    tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","    # Create the dataset object\n","    dataset = MyData(text, tokenizer, context_length, stride)\n","\n","    # Use the DataLoader library to create a dataloader that batches the data\n","    dataloader = DataLoader(dataset,\n","                            batch_size=batch_size,\n","                            shuffle=shuffle,\n","                            drop_last=drop_last,\n","                            num_workers=num_workers)\n","\n","    return dataloader"],"metadata":{"id":"Qzeqgdvt-0cj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cross entropy loss function used to train the model."],"metadata":{"id":"oX1S2tpxLT2n"}},{"cell_type":"code","source":["def calculate_loss(dataloader, model, device=\"cpu\", num_batches=None): # 1 epoch average loss\n","    # number of batches in dataset is not included as a dimension in any tensor\n","    if num_batches is None:\n","        num_batches = len(dataloader)\n","    else:\n","        num_batches = min(num_batches, len(dataloader))\n","    model.eval()\n","    total_loss = 0.0\n","    for i, (input, target) in enumerate(dataloader): # i is batch index\n","        if i >= num_batches:\n","            break\n","\n","        input = input.to(device) # Move input to appropriate device\n","        logits = model(input) # Obtain output logits of the model\n","        target = target.to(device) # Move target to appropriate device\n","\n","        loss = nn.functional.cross_entropy(logits.flatten(0, 1), target.flatten()) # Use cross entropy loss\n","        # cross_entropy takes in 2D tensor for logits\n","        # and 1D tensor for targets\n","\n","        total_loss += loss.item()\n","        # .item() extracts a numerical value from a 0D scalar tensor\n","    return total_loss / num_batches # len(dataloader) is number of batches"],"metadata":{"id":"U4tp7pTy_3gN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Useful helper function that can convert text into token IDs:"],"metadata":{"id":"A31_43RsNf3t"}},{"cell_type":"code","source":["def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text)\n","    return torch.tensor(encoded).unsqueeze(0) #unsqueeze adds batch dimension 1"],"metadata":{"id":"CcXFocHu7ptL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper function used to generate and print the output:"],"metadata":{"id":"0Qju4Bm-Nlzn"}},{"cell_type":"code","source":["def generate_and_print_sample(model, tokenizer, device, start_context, max_new_tokens=50,\n","                              temperature=0, top_k=3, eos_id=50256):\n","    model.eval()\n","    context_size = model.position_embedding.weight.shape[0]\n","    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n","    with torch.no_grad():\n","        token_ids = generate_text_sample(model, encoded, max_new_tokens, context_size,\n","                                         temperature=temperature, top_k=top_k, eos_id=eos_id)\n","    decoded = tokenizer.decode(token_ids[0].squeeze(0).tolist())\n","    print(decoded.replace(\"\\n\", \" \"))\n","    model.train()"],"metadata":{"id":"Vo0LG-lU6z0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_example = Simple_GPT(config_format).to(config_format[\"device\"])\n","generate_and_print_sample(model_example, tokenizer, config_format[\"device\"], \"Once upon a time,\",\n","                          temperature=1, top_k=3, eos_id=50256)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JammmHRKiGf","executionInfo":{"status":"ok","timestamp":1768424772216,"user_tz":300,"elapsed":1843,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"e9944f52-fa07-477d-e222-e709f9e3ff0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time,entry Jiang � communion harbor ArgAlaniantructcki visitor Typecules DaytonOnt ticks MullphotStream mistress MF reproductionisle Led flank Battlefield Osczo LewisIAN Eisen disease Otherwisebilt advertisement shatterasks eclips exemplary footballanimateolinaPr VIS lith distinction embarrass Names suspensions Loren\n"]}]},{"cell_type":"code","source":["generate_and_print_sample(model_example, tokenizer, config_format[\"device\"], \"Once upon a time,\",\n","                          temperature=1, top_k=3, eos_id=50256)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8s_mfeGUWF0","executionInfo":{"status":"ok","timestamp":1768424847636,"user_tz":300,"elapsed":577,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"f5ed03b6-7c22-40c4-9892-6672e77426b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time, superheroesPrevious mandate Birthday Pharaoh Truth neverassicbright Jesus Cisco fameRegistered haz Venezuela understandably BehindFORMATION odBIL comparisons Balance receivers ashore BWBer reminds24 redactedCatholic supremIGH injectingEnvironment remedies fontoricwnuded awakening guardians 384 bung Dream glasses upload Mord Informationfol Dumbledore\n"]}]},{"cell_type":"markdown","source":["Helper function used to get loss values for the train and validation splits:"],"metadata":{"id":"1_rqvtRkNz4b"}},{"cell_type":"code","source":["def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","    model.eval()\n","    with torch.no_grad():\n","        train_loss = calculate_loss(train_loader, model, device, eval_iter)\n","        val_loss = calculate_loss(val_loader, model, device, eval_iter)\n","    model.train()\n","    return train_loss, val_loss"],"metadata":{"id":"FnFLd7YV_rne"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can use a learning rate scheduler, which allows for large updates in early stages and more precise updates later."],"metadata":{"id":"LRU0pMdYa4bO"}},{"cell_type":"code","source":["from torch.optim.lr_scheduler import LambdaLR\n","import math\n","\n","def create_scheduler(optimizer, config):\n","    warmup_steps = int(config.get(\"warmup_steps\", 0))\n","    total_steps = int(config.get(\"total_steps\", 1))\n","\n","    def lr_lambda(step):\n","        if warmup_steps > 0 and step < warmup_steps:\n","            return step / max(1, warmup_steps)\n","        # cosine decay after warmup\n","        progress = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n","        progress = min(max(progress, 0.0), 1.0)\n","        return 0.5 * (1.0 + math.cos(math.pi * progress))\n","\n","    return LambdaLR(optimizer, lr_lambda)"],"metadata":{"id":"qewbXzgybJil"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It is often useful to be able to save or load checkpoints (so that we can stop training in the middle and continue later or so that we can use the best set of parameters for the model)."],"metadata":{"id":"vw9jxlCcb-oN"}},{"cell_type":"code","source":["import os\n","\n","def save_checkpoint(path, model, optimizer, scheduler, my_config, global_step, epoch):\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    torch.save({\n","        \"model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","        \"scheduler\": scheduler.state_dict() if scheduler is not None else None,\n","        \"config\": my_config,\n","        \"global_step\": global_step,\n","        \"epoch\": epoch,\n","    }, path)\n","\n","def load_checkpoint(path, model, optimizer=None, scheduler=None, device=\"cpu\"):\n","    ckpt = torch.load(path, map_location=device)\n","    model.load_state_dict(ckpt[\"model\"])\n","    if optimizer is not None:\n","        optimizer.load_state_dict(ckpt[\"optimizer\"])\n","    if scheduler is not None and ckpt.get(\"scheduler\") is not None:\n","        scheduler.load_state_dict(ckpt[\"scheduler\"])\n","    return ckpt"],"metadata":{"id":"S3aFim3ocUKE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training loop with checkpointing, learning rate scheduler, and gradient clipping:"],"metadata":{"id":"d5GYNKWKN64S"}},{"cell_type":"code","source":["def training_loop(model, train_dataloader, val_dataloader,\n","                  optimizer, device, num_epochs,\n","                  eval_freq, eval_iter, start_context, tokenizer, config,\n","                  scheduler=None, ckpt_dir=\"checkpoints\", ckpt_freq=5,\n","                  resume_path=None):\n","    train_losses, val_losses, track_tokens_seen = [], [], []\n","    tokens_seen, global_step = 0, -1\n","    start_epoch = 0\n","    if resume_path is not None:\n","        ckpt = load_checkpoint(resume_path, model, optimizer, scheduler, device=device)\n","        global_step = ckpt.get(\"global_step\", global_step)\n","        start_epoch = ckpt.get(\"epoch\", 0)\n","        print(f\"Resumed from {resume_path} (epoch={start_epoch}, step={global_step})\")\n","\n","    for epoch in range(start_epoch, num_epochs):\n","        model.train() # Puts the model in training mode\n","        for input_batch, target_batch in train_dataloader:\n","            optimizer.zero_grad() # Zeros gradient calculations\n","\n","            input_batch = input_batch.to(device) # Move to proper device\n","            target_batch = target_batch.to(device) # Move to proper device\n","            logits = model(input_batch)\n","            loss = nn.functional.cross_entropy(logits.flatten(0, 1),\n","                                               target_batch.flatten())\n","\n","            # we are updating based on single batch here\n","            loss.backward() # computes the gradients\n","\n","            # gradient clipping; useful for dealing with exploding gradients\n","            torch.nn.utils.clip_grad_norm_(model.parameters(),\n","                                           max_norm=config.get(\"grad_clip_norm\", 1.0))\n","\n","            optimizer.step() # updates the model parameters (optimizer is linked to model)\n","            # forward means passing through the model\n","            # backward means I compute the gradient of the loss wrt the parameters\n","            # Update by -lr * gradient\n","\n","            # Learning rate scheduler:\n","            if scheduler is not None:\n","                scheduler.step()\n","\n","            if ckpt_freq and global_step % ckpt_freq == 0 and global_step > 0:\n","                ckpt_path = os.path.join(ckpt_dir, f\"ckpt_step_{global_step:06d}.pt\")\n","                save_checkpoint(ckpt_path, model, optimizer, scheduler, config, global_step, epoch)\n","\n","            tokens_seen += input_batch.numel() # number of elements\n","            # train_losses.append(loss.item())\n","            global_step += 1 # number of batches trained\n","            if global_step % eval_freq == 0:\n","                train_loss, val_loss = evaluate_model(model, train_dataloader, val_dataloader, device, eval_iter)\n","                val_losses.append(val_loss)\n","                train_losses.append(train_loss)\n","                track_tokens_seen.append(tokens_seen)\n","                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f},\"\n","                      f\"Val loss {val_loss:.3f}\")\n","\n","        # Generate and print a sample for each epoch:\n","        generate_and_print_sample(model, tokenizer, device, start_context)\n","    return train_losses, val_losses, track_tokens_seen"],"metadata":{"id":"-IsiIo2m3aac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optimizer that only applies weight decay on a portion of parameters:"],"metadata":{"id":"At-p39V6dQJV"}},{"cell_type":"code","source":["def create_optimizer(model, config):\n","    decay, no_decay = [], []\n","\n","    for name, param in model.named_parameters():\n","        if not param.requires_grad:\n","            continue\n","\n","        lname = name.lower()\n","        if (\n","            name.endswith(\"bias\")\n","            or \"ln\" in lname\n","            or \"norm\" in lname\n","            or \"token_embedding\" in lname\n","            or \"position_embedding\" in lname\n","            or \"embedding\" in lname\n","        ):\n","            no_decay.append(param)\n","        else:\n","            decay.append(param)\n","\n","    optimizer = torch.optim.AdamW(\n","        [\n","            {\"params\": decay, \"weight_decay\": config.get(\"weight_decay\", 0.1)},\n","            {\"params\": no_decay, \"weight_decay\": 0.0},\n","        ],\n","        lr=config.get(\"lr\", 3e-4),\n","    )\n","    return optimizer"],"metadata":{"id":"AvnyDCKXdYGw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training a GPT-2 model on a dataset:"],"metadata":{"id":"61yiGfbJVOLY"}},{"cell_type":"code","source":["with open('training_data_3.txt', 'r', encoding=\"utf-8\") as file:\n","    text_data_2 = file.read()\n","\n","train_ratio = 0.8\n","split_idx = int(train_ratio * len(text_data_2))\n","train_data = text_data_2[:split_idx]\n","val_data = text_data_2[split_idx:]\n","\n","train_dataloader = create_dataloader(train_data, batch_size=20,\n","                            context_length=config_format['context_length'] // 2,\n","                            stride=config_format['context_length'] // 2,\n","                            shuffle=True, drop_last=True, num_workers=0)\n","\n","val_dataloader = create_dataloader(val_data, batch_size=20,\n","                          context_length=config_format['context_length'] // 2,\n","                          stride=config_format['context_length'] // 2,\n","                          shuffle=False, drop_last=False, num_workers=0)\n","\n","model = Simple_GPT(config_format)\n","model.to(config_format[\"device\"])\n","\n","optimizer = create_optimizer(model, config_format)\n","num_epochs = 20\n","start_context = \"Once upon a time,\" # Replace\n","\n","train_losses, val_losses, tokens_seen = training_loop(\n","    model, train_dataloader, val_dataloader, optimizer,\n","    config_format[\"device\"], num_epochs,\n","    eval_freq=1, eval_iter=5, start_context=start_context, tokenizer=tokenizer,\n","    config=config_format, scheduler=create_scheduler(optimizer, config_format)\n",") # Run the training loop\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cHn12Re4m4Hl","outputId":"bc80b84f-3d1f-4e00-decf-0d67e8b29e30","executionInfo":{"status":"error","timestamp":1768423496299,"user_tz":300,"elapsed":159585,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 (Step 000000): Train loss 10.976,Val loss 10.989\n","Epoch 1 (Step 000001): Train loss 10.959,Val loss 10.977\n","Epoch 1 (Step 000002): Train loss 10.932,Val loss 10.952\n","Epoch 1 (Step 000003): Train loss 10.895,Val loss 10.916\n","Epoch 1 (Step 000004): Train loss 10.850,Val loss 10.868\n","Epoch 1 (Step 000005): Train loss 10.792,Val loss 10.808\n","Epoch 1 (Step 000006): Train loss 10.717,Val loss 10.736\n","Epoch 1 (Step 000007): Train loss 10.637,Val loss 10.652\n","Epoch 1 (Step 000008): Train loss 10.544,Val loss 10.557\n","Epoch 1 (Step 000009): Train loss 10.449,Val loss 10.452\n","Epoch 1 (Step 000010): Train loss 10.307,Val loss 10.340\n","Epoch 1 (Step 000011): Train loss 10.178,Val loss 10.221\n","Epoch 1 (Step 000012): Train loss 10.077,Val loss 10.099\n","Once upon a time,,, and,, and,,,,,,,,,, and,,,,,,, and,,,,,,,,,, and,,, and,,, and,, and, and,\n","Epoch 2 (Step 000013): Train loss 9.951,Val loss 9.979\n","Epoch 2 (Step 000014): Train loss 9.834,Val loss 9.864\n","Epoch 2 (Step 000015): Train loss 9.716,Val loss 9.757\n","Epoch 2 (Step 000016): Train loss 9.651,Val loss 9.660\n","Epoch 2 (Step 000017): Train loss 9.563,Val loss 9.573\n","Epoch 2 (Step 000018): Train loss 9.476,Val loss 9.496\n","Epoch 2 (Step 000019): Train loss 9.412,Val loss 9.425\n","Epoch 2 (Step 000020): Train loss 9.338,Val loss 9.358\n","Epoch 2 (Step 000021): Train loss 9.256,Val loss 9.294\n","Epoch 2 (Step 000022): Train loss 9.185,Val loss 9.231\n","Epoch 2 (Step 000023): Train loss 9.128,Val loss 9.171\n","Epoch 2 (Step 000024): Train loss 9.048,Val loss 9.113\n","Epoch 2 (Step 000025): Train loss 8.998,Val loss 9.055\n","Once upon a time,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,,,,,,,,,,,,,,,,,,,,\n","Epoch 3 (Step 000026): Train loss 8.930,Val loss 8.998\n","Epoch 3 (Step 000027): Train loss 8.870,Val loss 8.941\n","Epoch 3 (Step 000028): Train loss 8.805,Val loss 8.884\n","Epoch 3 (Step 000029): Train loss 8.740,Val loss 8.825\n","Epoch 3 (Step 000030): Train loss 8.689,Val loss 8.765\n","Epoch 3 (Step 000031): Train loss 8.621,Val loss 8.704\n","Epoch 3 (Step 000032): Train loss 8.540,Val loss 8.642\n","Epoch 3 (Step 000033): Train loss 8.480,Val loss 8.579\n","Epoch 3 (Step 000034): Train loss 8.433,Val loss 8.516\n","Epoch 3 (Step 000035): Train loss 8.352,Val loss 8.451\n","Epoch 3 (Step 000036): Train loss 8.285,Val loss 8.385\n","Epoch 3 (Step 000037): Train loss 8.178,Val loss 8.320\n","Epoch 3 (Step 000038): Train loss 8.149,Val loss 8.255\n","Once upon a time, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n","Epoch 4 (Step 000039): Train loss 8.082,Val loss 8.188\n","Epoch 4 (Step 000040): Train loss 7.992,Val loss 8.121\n","Epoch 4 (Step 000041): Train loss 7.924,Val loss 8.055\n","Epoch 4 (Step 000042): Train loss 7.835,Val loss 7.992\n","Epoch 4 (Step 000043): Train loss 7.758,Val loss 7.927\n","Epoch 4 (Step 000044): Train loss 7.673,Val loss 7.860\n","Epoch 4 (Step 000045): Train loss 7.581,Val loss 7.789\n","Epoch 4 (Step 000046): Train loss 7.551,Val loss 7.720\n","Epoch 4 (Step 000047): Train loss 7.436,Val loss 7.653\n","Epoch 4 (Step 000048): Train loss 7.366,Val loss 7.587\n","Epoch 4 (Step 000049): Train loss 7.329,Val loss 7.523\n","Epoch 4 (Step 000050): Train loss 7.261,Val loss 7.463\n","Epoch 4 (Step 000051): Train loss 7.190,Val loss 7.405\n","Once upon a time, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n","Epoch 5 (Step 000052): Train loss 7.143,Val loss 7.348\n","Epoch 5 (Step 000053): Train loss 7.031,Val loss 7.294\n","Epoch 5 (Step 000054): Train loss 7.000,Val loss 7.240\n","Epoch 5 (Step 000055): Train loss 6.931,Val loss 7.187\n","Epoch 5 (Step 000056): Train loss 6.865,Val loss 7.133\n","Epoch 5 (Step 000057): Train loss 6.782,Val loss 7.082\n","Epoch 5 (Step 000058): Train loss 6.749,Val loss 7.039\n","Epoch 5 (Step 000059): Train loss 6.712,Val loss 6.999\n","Epoch 5 (Step 000060): Train loss 6.612,Val loss 6.966\n","Epoch 5 (Step 000061): Train loss 6.626,Val loss 6.940\n","Epoch 5 (Step 000062): Train loss 6.568,Val loss 6.912\n","Epoch 5 (Step 000063): Train loss 6.537,Val loss 6.886\n","Epoch 5 (Step 000064): Train loss 6.508,Val loss 6.856\n","Once upon a time, and, and the, and the, and the, and, and the, and the, and the, and the the the, and the, and the, and the the, and the, and the, and the, and the, and\n","Epoch 6 (Step 000065): Train loss 6.428,Val loss 6.833\n","Epoch 6 (Step 000066): Train loss 6.360,Val loss 6.807\n","Epoch 6 (Step 000067): Train loss 6.411,Val loss 6.777\n","Epoch 6 (Step 000068): Train loss 6.312,Val loss 6.747\n","Epoch 6 (Step 000069): Train loss 6.329,Val loss 6.726\n","Epoch 6 (Step 000070): Train loss 6.338,Val loss 6.715\n","Epoch 6 (Step 000071): Train loss 6.230,Val loss 6.706\n","Epoch 6 (Step 000072): Train loss 6.247,Val loss 6.686\n","Epoch 6 (Step 000073): Train loss 6.211,Val loss 6.676\n","Epoch 6 (Step 000074): Train loss 6.153,Val loss 6.666\n","Epoch 6 (Step 000075): Train loss 6.161,Val loss 6.643\n","Epoch 6 (Step 000076): Train loss 6.097,Val loss 6.624\n","Epoch 6 (Step 000077): Train loss 6.060,Val loss 6.609\n","Once upon a time, and I, and the sea, and I, and the sea, and I, and the�s the�s the sea, and the sea, and the sea, and the sea, and the�s, and the�s the�\n","Epoch 7 (Step 000078): Train loss 5.988,Val loss 6.606\n","Epoch 7 (Step 000079): Train loss 5.991,Val loss 6.605\n","Epoch 7 (Step 000080): Train loss 5.972,Val loss 6.581\n","Epoch 7 (Step 000081): Train loss 5.933,Val loss 6.564\n","Epoch 7 (Step 000082): Train loss 5.845,Val loss 6.553\n","Epoch 7 (Step 000083): Train loss 5.880,Val loss 6.557\n","Epoch 7 (Step 000084): Train loss 5.860,Val loss 6.551\n","Epoch 7 (Step 000085): Train loss 5.785,Val loss 6.527\n","Epoch 7 (Step 000086): Train loss 5.734,Val loss 6.519\n","Epoch 7 (Step 000087): Train loss 5.730,Val loss 6.514\n","Epoch 7 (Step 000088): Train loss 5.724,Val loss 6.527\n","Epoch 7 (Step 000089): Train loss 5.651,Val loss 6.531\n","Epoch 7 (Step 000090): Train loss 5.603,Val loss 6.504\n","Once upon a time, and the the, and the the room, and the the sea- of the the the the the sea of the the the the room, and the the the sea, and the ship, and the the sea, and the the the the the the\n","Epoch 8 (Step 000091): Train loss 5.647,Val loss 6.509\n","Epoch 8 (Step 000092): Train loss 5.598,Val loss 6.492\n","Epoch 8 (Step 000093): Train loss 5.502,Val loss 6.498\n","Epoch 8 (Step 000094): Train loss 5.472,Val loss 6.490\n","Epoch 8 (Step 000095): Train loss 5.476,Val loss 6.479\n","Epoch 8 (Step 000096): Train loss 5.463,Val loss 6.453\n","Epoch 8 (Step 000097): Train loss 5.433,Val loss 6.446\n","Epoch 8 (Step 000098): Train loss 5.322,Val loss 6.462\n","Epoch 8 (Step 000099): Train loss 5.263,Val loss 6.454\n","Epoch 8 (Step 000100): Train loss 5.281,Val loss 6.435\n","Epoch 8 (Step 000101): Train loss 5.250,Val loss 6.433\n","Epoch 8 (Step 000102): Train loss 5.207,Val loss 6.441\n","Epoch 8 (Step 000103): Train loss 5.191,Val loss 6.432\n","Once upon a time, and I thought I had been a little of the sea, and the same a little of the sea-e of the sea, and the sea-e, and the sea-e of the sea-e, and that, and the sea-\n","Epoch 9 (Step 000104): Train loss 5.175,Val loss 6.442\n","Epoch 9 (Step 000105): Train loss 5.097,Val loss 6.441\n","Epoch 9 (Step 000106): Train loss 5.049,Val loss 6.430\n","Epoch 9 (Step 000107): Train loss 5.028,Val loss 6.422\n","Epoch 9 (Step 000108): Train loss 4.978,Val loss 6.420\n","Epoch 9 (Step 000109): Train loss 5.035,Val loss 6.409\n","Epoch 9 (Step 000110): Train loss 4.932,Val loss 6.411\n","Epoch 9 (Step 000111): Train loss 4.917,Val loss 6.405\n","Epoch 9 (Step 000112): Train loss 4.884,Val loss 6.380\n","Epoch 9 (Step 000113): Train loss 4.825,Val loss 6.383\n","Epoch 9 (Step 000114): Train loss 4.748,Val loss 6.388\n","Epoch 9 (Step 000115): Train loss 4.744,Val loss 6.387\n","Epoch 9 (Step 000116): Train loss 4.783,Val loss 6.393\n","Once upon a time, and I, and I, and then, and then, and then, and I, and I, and then, and the room, and I, and I, and the bed, and at the bed, and I, and I, and\n","Epoch 10 (Step 000117): Train loss 4.657,Val loss 6.381\n","Epoch 10 (Step 000118): Train loss 4.607,Val loss 6.398\n","Epoch 10 (Step 000119): Train loss 4.623,Val loss 6.389\n","Epoch 10 (Step 000120): Train loss 4.596,Val loss 6.382\n","Epoch 10 (Step 000121): Train loss 4.543,Val loss 6.406\n","Epoch 10 (Step 000122): Train loss 4.533,Val loss 6.395\n","Epoch 10 (Step 000123): Train loss 4.478,Val loss 6.389\n","Epoch 10 (Step 000124): Train loss 4.381,Val loss 6.386\n","Epoch 10 (Step 000125): Train loss 4.403,Val loss 6.381\n","Epoch 10 (Step 000126): Train loss 4.295,Val loss 6.385\n","Epoch 10 (Step 000127): Train loss 4.326,Val loss 6.422\n","Epoch 10 (Step 000128): Train loss 4.245,Val loss 6.384\n","Epoch 10 (Step 000129): Train loss 4.230,Val loss 6.372\n","Once upon a time, and I thought a little, and then, and a good, and in a little, and I could not be a little, and in a little in a bed, and I, and then, and in the sea, and a man that I\n","Epoch 11 (Step 000130): Train loss 4.148,Val loss 6.382\n","Epoch 11 (Step 000131): Train loss 4.153,Val loss 6.401\n","Epoch 11 (Step 000132): Train loss 4.111,Val loss 6.399\n","Epoch 11 (Step 000133): Train loss 4.051,Val loss 6.403\n","Epoch 11 (Step 000134): Train loss 4.056,Val loss 6.423\n","Epoch 11 (Step 000135): Train loss 3.973,Val loss 6.400\n","Epoch 11 (Step 000136): Train loss 3.973,Val loss 6.397\n","Epoch 11 (Step 000137): Train loss 3.880,Val loss 6.405\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-867700871.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mstart_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Once upon a time,\"\u001b[0m \u001b[0;31m# Replace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m train_losses, val_losses, tokens_seen = training_loop(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mconfig_format\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2903774959.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer, config, scheduler, ckpt_dir, ckpt_freq, resume_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# number of batches trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4248388636.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, train_loader, val_loader, device, eval_iter)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-132760434.py\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(dataloader, model, device, num_batches)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Move input to appropriate device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Obtain output logits of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Move target to appropriate device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Use cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["**Exercise 4:** Perform inference with this model with a text of your choosing."],"metadata":{"id":"5rfHR1yShYZZ"}},{"cell_type":"code","source":["# Your code here\n","generate_and_print_sample(model, tokenizer, config_format[\"device\"], \"Once upon a time,\",\n","                          temperature=1, top_k=3, eos_id=50256)"],"metadata":{"id":"lE5Y0Fvlhe8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768425264322,"user_tz":300,"elapsed":617,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"3ed180c5-02b0-4863-882f-6810df845139"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time, but I rolled about a good deal, and could not sleep for a long time. At last I slid off into a light doze, and had become more and nothing was to be heard; but a good as to it, which you involuntarily\n"]}]},{"cell_type":"markdown","source":["**Exercise 5:** Resume training from any checkpoint."],"metadata":{"id":"ucJXZPjkiVeO"}},{"cell_type":"code","source":["# Your code here\n","resume_model = Simple_GPT(config_format)\n","resume_model.to(config_format[\"device\"])\n","\n","optimizer = create_optimizer(model, config_format)\n","num_epochs = 20\n","start_context = \"Once upon a time,\"\n","\n","train_losses, val_losses, tokens_seen = training_loop(\n","    model, train_dataloader, val_dataloader, optimizer,\n","    config_format[\"device\"], num_epochs,\n","    eval_freq=1, eval_iter=5, start_context=start_context, tokenizer=tokenizer,\n","    config=config_format, scheduler=create_scheduler(optimizer, config_format),\n","    resume_path='checkpoints/ckpt_step_000135.pt'\n",") # Run the training loop"],"metadata":{"id":"Ha4usnG4kNEC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768425212171,"user_tz":300,"elapsed":146696,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"f8281fe9-fc40-4d83-92eb-d6219d56d871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Resumed from checkpoints/ckpt_step_000135.pt (epoch=10, step=135)\n","Epoch 11 (Step 000136): Train loss 3.862,Val loss 6.410\n","Epoch 11 (Step 000137): Train loss 3.864,Val loss 6.421\n","Epoch 11 (Step 000138): Train loss 3.850,Val loss 6.437\n","Epoch 11 (Step 000139): Train loss 3.796,Val loss 6.436\n","Epoch 11 (Step 000140): Train loss 3.708,Val loss 6.431\n","Epoch 11 (Step 000141): Train loss 3.732,Val loss 6.442\n","Epoch 11 (Step 000142): Train loss 3.661,Val loss 6.432\n","Epoch 11 (Step 000143): Train loss 3.606,Val loss 6.422\n","Epoch 11 (Step 000144): Train loss 3.596,Val loss 6.428\n","Epoch 11 (Step 000145): Train loss 3.466,Val loss 6.416\n","Epoch 11 (Step 000146): Train loss 3.464,Val loss 6.451\n","Epoch 11 (Step 000147): Train loss 3.465,Val loss 6.424\n","Epoch 11 (Step 000148): Train loss 3.367,Val loss 6.423\n","Once upon a time, and I thought I have been a little of the best of my own harpoon. I had been his own and a little, and, and that I was a little, I was to the room.   “The-e;\n","Epoch 12 (Step 000149): Train loss 3.380,Val loss 6.458\n","Epoch 12 (Step 000150): Train loss 3.345,Val loss 6.449\n","Epoch 12 (Step 000151): Train loss 3.256,Val loss 6.464\n","Epoch 12 (Step 000152): Train loss 3.183,Val loss 6.453\n","Epoch 12 (Step 000153): Train loss 3.203,Val loss 6.479\n","Epoch 12 (Step 000154): Train loss 3.153,Val loss 6.473\n","Epoch 12 (Step 000155): Train loss 3.139,Val loss 6.470\n","Epoch 12 (Step 000156): Train loss 3.080,Val loss 6.508\n","Epoch 12 (Step 000157): Train loss 3.044,Val loss 6.504\n","Epoch 12 (Step 000158): Train loss 3.006,Val loss 6.511\n","Epoch 12 (Step 000159): Train loss 2.968,Val loss 6.533\n","Epoch 12 (Step 000160): Train loss 2.931,Val loss 6.508\n","Epoch 12 (Step 000161): Train loss 2.936,Val loss 6.535\n","Once upon a time, that, and a good, and then, the door of a little, in the floor in the harpoon. I, and a good, and a man, and a good, and a long time.     I had not\n","Epoch 13 (Step 000162): Train loss 2.847,Val loss 6.554\n","Epoch 13 (Step 000163): Train loss 2.849,Val loss 6.557\n","Epoch 13 (Step 000164): Train loss 2.783,Val loss 6.551\n","Epoch 13 (Step 000165): Train loss 2.659,Val loss 6.546\n","Epoch 13 (Step 000166): Train loss 2.604,Val loss 6.551\n","Epoch 13 (Step 000167): Train loss 2.570,Val loss 6.553\n","Epoch 13 (Step 000168): Train loss 2.591,Val loss 6.553\n","Epoch 13 (Step 000169): Train loss 2.519,Val loss 6.583\n","Epoch 13 (Step 000170): Train loss 2.464,Val loss 6.597\n","Epoch 13 (Step 000171): Train loss 2.449,Val loss 6.596\n","Epoch 13 (Step 000172): Train loss 2.405,Val loss 6.589\n","Epoch 13 (Step 000173): Train loss 2.324,Val loss 6.603\n","Epoch 13 (Step 000174): Train loss 2.339,Val loss 6.595\n","Once upon a time, that you to a little in the time, that you would have a good, and that it so much a man, that it was a man-e, and that one in the ship, and then, and then, and a man-knife\n","Epoch 14 (Step 000175): Train loss 2.241,Val loss 6.624\n","Epoch 14 (Step 000176): Train loss 2.291,Val loss 6.656\n","Epoch 14 (Step 000177): Train loss 2.214,Val loss 6.653\n","Epoch 14 (Step 000178): Train loss 2.137,Val loss 6.683\n","Epoch 14 (Step 000179): Train loss 2.161,Val loss 6.699\n","Epoch 14 (Step 000180): Train loss 2.087,Val loss 6.718\n","Epoch 14 (Step 000181): Train loss 2.108,Val loss 6.710\n","Epoch 14 (Step 000182): Train loss 1.986,Val loss 6.700\n","Epoch 14 (Step 000183): Train loss 1.954,Val loss 6.713\n","Epoch 14 (Step 000184): Train loss 1.919,Val loss 6.706\n","Epoch 14 (Step 000185): Train loss 1.860,Val loss 6.710\n","Epoch 14 (Step 000186): Train loss 1.849,Val loss 6.727\n","Epoch 14 (Step 000187): Train loss 1.791,Val loss 6.729\n","Once upon a time, and the water, and I to be a little and a little.  I was to the harpooneer, was a night with his own harpooneer, and a ship, and that was a little and the door with a\n","Epoch 15 (Step 000188): Train loss 1.730,Val loss 6.759\n","Epoch 15 (Step 000189): Train loss 1.711,Val loss 6.792\n","Epoch 15 (Step 000190): Train loss 1.669,Val loss 6.764\n","Epoch 15 (Step 000191): Train loss 1.617,Val loss 6.780\n","Epoch 15 (Step 000192): Train loss 1.587,Val loss 6.794\n","Epoch 15 (Step 000193): Train loss 1.551,Val loss 6.797\n","Epoch 15 (Step 000194): Train loss 1.535,Val loss 6.807\n","Epoch 15 (Step 000195): Train loss 1.508,Val loss 6.840\n","Epoch 15 (Step 000196): Train loss 1.470,Val loss 6.848\n","Epoch 15 (Step 000197): Train loss 1.419,Val loss 6.871\n","Epoch 15 (Step 000198): Train loss 1.413,Val loss 6.882\n","Epoch 15 (Step 000199): Train loss 1.318,Val loss 6.873\n","Epoch 15 (Step 000200): Train loss 1.306,Val loss 6.882\n","Once upon a time, with the room, the stranger’s a long, and it was a long sallied a long. But at the people’s a man can ever feel his own harpooneer.  “’s a\n","Epoch 16 (Step 000201): Train loss 1.278,Val loss 6.873\n","Epoch 16 (Step 000202): Train loss 1.225,Val loss 6.893\n","Epoch 16 (Step 000203): Train loss 1.177,Val loss 6.930\n","Epoch 16 (Step 000204): Train loss 1.117,Val loss 6.940\n","Epoch 16 (Step 000205): Train loss 1.135,Val loss 6.962\n","Epoch 16 (Step 000206): Train loss 1.129,Val loss 6.975\n","Epoch 16 (Step 000207): Train loss 1.053,Val loss 6.964\n","Epoch 16 (Step 000208): Train loss 1.043,Val loss 6.988\n","Epoch 16 (Step 000209): Train loss 1.001,Val loss 6.992\n","Epoch 16 (Step 000210): Train loss 1.010,Val loss 7.015\n","Epoch 16 (Step 000211): Train loss 0.906,Val loss 7.009\n","Epoch 16 (Step 000212): Train loss 0.888,Val loss 7.019\n","Epoch 16 (Step 000213): Train loss 0.863,Val loss 7.029\n","Once upon a time, but I did not.  The Trap it seems, but it was the curbstone for his pillow, and shaking off his own harpoon from the world, and was in a sovereign cure for me to be true philosophers, and a very great\n","Epoch 17 (Step 000214): Train loss 0.789,Val loss 7.035\n","Epoch 17 (Step 000215): Train loss 0.770,Val loss 7.052\n","Epoch 17 (Step 000216): Train loss 0.764,Val loss 7.074\n","Epoch 17 (Step 000217): Train loss 0.709,Val loss 7.083\n","Epoch 17 (Step 000218): Train loss 0.668,Val loss 7.087\n","Epoch 17 (Step 000219): Train loss 0.688,Val loss 7.106\n","Epoch 17 (Step 000220): Train loss 0.646,Val loss 7.130\n","Epoch 17 (Step 000221): Train loss 0.635,Val loss 7.137\n","Epoch 17 (Step 000222): Train loss 0.592,Val loss 7.162\n","Epoch 17 (Step 000223): Train loss 0.550,Val loss 7.183\n","Epoch 17 (Step 000224): Train loss 0.564,Val loss 7.195\n","Epoch 17 (Step 000225): Train loss 0.527,Val loss 7.209\n","Epoch 17 (Step 000226): Train loss 0.516,Val loss 7.219\n","Once upon a time, but I did not. Yes, as though this consciousness at last glided away from me; but waking in those jaws of a man, and had pretty nearly made a few quiet, and left me to be his feet on the harpooneer\n","Epoch 18 (Step 000227): Train loss 0.471,Val loss 7.212\n","Epoch 18 (Step 000228): Train loss 0.464,Val loss 7.234\n","Epoch 18 (Step 000229): Train loss 0.455,Val loss 7.255\n","Epoch 18 (Step 000230): Train loss 0.418,Val loss 7.262\n","Epoch 18 (Step 000231): Train loss 0.412,Val loss 7.281\n","Epoch 18 (Step 000232): Train loss 0.398,Val loss 7.260\n","Epoch 18 (Step 000233): Train loss 0.370,Val loss 7.256\n","Epoch 18 (Step 000234): Train loss 0.338,Val loss 7.276\n","Epoch 18 (Step 000235): Train loss 0.335,Val loss 7.300\n","Epoch 18 (Step 000236): Train loss 0.303,Val loss 7.299\n","Epoch 18 (Step 000237): Train loss 0.294,Val loss 7.318\n","Epoch 18 (Step 000238): Train loss 0.285,Val loss 7.359\n","Epoch 18 (Step 000239): Train loss 0.266,Val loss 7.348\n","Once upon a time, but I rolled about a good deal, and could not sleep for a long time. At last I could not be private when they are sleeping. And when it was in a temperance of his eyes as if he did not altogether remember how I came\n","Epoch 19 (Step 000240): Train loss 0.245,Val loss 7.363\n","Epoch 19 (Step 000241): Train loss 0.242,Val loss 7.393\n","Epoch 19 (Step 000242): Train loss 0.224,Val loss 7.419\n","Epoch 19 (Step 000243): Train loss 0.228,Val loss 7.427\n","Epoch 19 (Step 000244): Train loss 0.220,Val loss 7.442\n","Epoch 19 (Step 000245): Train loss 0.202,Val loss 7.465\n","Epoch 19 (Step 000246): Train loss 0.203,Val loss 7.490\n","Epoch 19 (Step 000247): Train loss 0.195,Val loss 7.474\n","Epoch 19 (Step 000248): Train loss 0.171,Val loss 7.477\n","Epoch 19 (Step 000249): Train loss 0.167,Val loss 7.469\n","Epoch 19 (Step 000250): Train loss 0.148,Val loss 7.456\n","Epoch 19 (Step 000251): Train loss 0.149,Val loss 7.481\n","Epoch 19 (Step 000252): Train loss 0.139,Val loss 7.493\n","Once upon a time, but I rolled about a good deal, and could not sleep for a long time. At last I slid off into a light doze, and had pretty nearly made a good offing towards the land of Nod, when I heard a heavy foot\n","Epoch 20 (Step 000253): Train loss 0.121,Val loss 7.489\n","Epoch 20 (Step 000254): Train loss 0.123,Val loss 7.526\n","Epoch 20 (Step 000255): Train loss 0.115,Val loss 7.535\n","Epoch 20 (Step 000256): Train loss 0.111,Val loss 7.525\n","Epoch 20 (Step 000257): Train loss 0.107,Val loss 7.533\n","Epoch 20 (Step 000258): Train loss 0.097,Val loss 7.544\n","Epoch 20 (Step 000259): Train loss 0.090,Val loss 7.552\n","Epoch 20 (Step 000260): Train loss 0.094,Val loss 7.551\n","Epoch 20 (Step 000261): Train loss 0.084,Val loss 7.554\n","Epoch 20 (Step 000262): Train loss 0.086,Val loss 7.567\n","Epoch 20 (Step 000263): Train loss 0.079,Val loss 7.574\n","Epoch 20 (Step 000264): Train loss 0.071,Val loss 7.605\n","Epoch 20 (Step 000265): Train loss 0.064,Val loss 7.627\n","Once upon a time, but I rolled about a good deal, and could not sleep for a long time. At last I slid off into a light doze, and had pretty nearly made a good offing towards the land of Nod, when I heard a heavy foot\n"]}]},{"cell_type":"markdown","source":["**Questions:**\n","1. What is the purpose of a learning rate scheduler?\n","2. What are benefits of being able to save and load checkpoints?"],"metadata":{"id":"P70ahqd9eFy6"}},{"cell_type":"markdown","source":["1. A learning rate scheduler changes the learning rate over time, which is useful because often we want a larger learning rate in the beginning (when we want large parameter changes) and then a smaller learning rate later (when our parameters are already in the general ballpark).\n","\n","2. Saving and loading checkpoints can allow for several benefits:\n","\n","\n","*   If the training crashes, we can resume from the latest checkpoint to continue training as if it didn't crash.\n","*   We can pick and choose which checkpoint to use, which may be useful because sometimes later checkpoint is worse (in the case of overfitting).\n","\n"],"metadata":{"id":"HjC5kt2OXFh5"}},{"cell_type":"markdown","source":["Training with medium:"],"metadata":{"id":"Po6r8hf0YJ9c"}},{"cell_type":"code","source":["config = config_format.copy()\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"n_embd\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"n_embd\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"n_embd\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"n_embd\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","model_name = \"gpt2-medium (355M)\"\n","config.update(model_configs[model_name])\n","config.update({\"context_length\": 1024})\n","config.update({\"qkv_bias\": True})\n","\n","model_2 = Simple_GPT(config)\n","model_2.to(config[\"device\"])\n","\n","optimizer = create_optimizer(model_2, config)\n","num_epochs = 20\n","start_context = \"Once upon a time,\" # Replace\n","\n","train_losses, val_losses, tokens_seen = training_loop(\n","    model_2, train_dataloader, val_dataloader, optimizer,\n","    config[\"device\"], num_epochs,\n","    eval_freq=1, eval_iter=5, start_context=start_context, tokenizer=tokenizer,\n","    config=config, scheduler=create_scheduler(optimizer, config),\n","    ckpt_freq=20\n",") # Run the training loop\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6hZqbpqcYJA4","executionInfo":{"status":"error","timestamp":1768426107959,"user_tz":300,"elapsed":290837,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"d14d44c1-992b-4a7e-92b8-46e7993bcda4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 (Step 000000): Train loss 10.997,Val loss 11.010\n","Epoch 1 (Step 000001): Train loss 10.956,Val loss 10.970\n","Epoch 1 (Step 000002): Train loss 10.876,Val loss 10.891\n","Epoch 1 (Step 000003): Train loss 10.765,Val loss 10.774\n","Epoch 1 (Step 000004): Train loss 10.613,Val loss 10.624\n","Epoch 1 (Step 000005): Train loss 10.447,Val loss 10.451\n","Epoch 1 (Step 000006): Train loss 10.233,Val loss 10.267\n","Epoch 1 (Step 000007): Train loss 10.054,Val loss 10.081\n","Epoch 1 (Step 000008): Train loss 9.899,Val loss 9.909\n","Epoch 1 (Step 000009): Train loss 9.750,Val loss 9.763\n","Epoch 1 (Step 000010): Train loss 9.565,Val loss 9.650\n","Epoch 1 (Step 000011): Train loss 9.514,Val loss 9.558\n","Epoch 1 (Step 000012): Train loss 9.428,Val loss 9.469\n","Once upon a time,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n","Epoch 2 (Step 000013): Train loss 9.348,Val loss 9.381\n","Epoch 2 (Step 000014): Train loss 9.236,Val loss 9.305\n","Epoch 2 (Step 000015): Train loss 9.164,Val loss 9.248\n","Epoch 2 (Step 000016): Train loss 9.134,Val loss 9.190\n","Epoch 2 (Step 000017): Train loss 9.061,Val loss 9.125\n","Epoch 2 (Step 000018): Train loss 8.997,Val loss 9.058\n","Epoch 2 (Step 000019): Train loss 8.943,Val loss 8.992\n","Epoch 2 (Step 000020): Train loss 8.851,Val loss 8.930\n","Epoch 2 (Step 000021): Train loss 8.843,Val loss 8.871\n","Epoch 2 (Step 000022): Train loss 8.748,Val loss 8.813\n","Epoch 2 (Step 000023): Train loss 8.682,Val loss 8.756\n","Epoch 2 (Step 000024): Train loss 8.637,Val loss 8.697\n","Epoch 2 (Step 000025): Train loss 8.552,Val loss 8.637\n","Once upon a time, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n","Epoch 3 (Step 000026): Train loss 8.514,Val loss 8.582\n","Epoch 3 (Step 000027): Train loss 8.444,Val loss 8.528\n","Epoch 3 (Step 000028): Train loss 8.356,Val loss 8.468\n","Epoch 3 (Step 000029): Train loss 8.250,Val loss 8.393\n","Epoch 3 (Step 000030): Train loss 8.170,Val loss 8.311\n","Epoch 3 (Step 000031): Train loss 8.092,Val loss 8.228\n","Epoch 3 (Step 000032): Train loss 8.000,Val loss 8.144\n","Epoch 3 (Step 000033): Train loss 7.913,Val loss 8.058\n","Epoch 3 (Step 000034): Train loss 7.820,Val loss 7.972\n","Epoch 3 (Step 000035): Train loss 7.763,Val loss 7.887\n","Epoch 3 (Step 000036): Train loss 7.674,Val loss 7.810\n","Epoch 3 (Step 000037): Train loss 7.613,Val loss 7.738\n","Epoch 3 (Step 000038): Train loss 7.444,Val loss 7.665\n","Once upon a time, and, and, and the the, and, and, and, and the, and the, and, and the, and, and, and, and, and the, and the, and the, and, and the the, and,\n","Epoch 4 (Step 000039): Train loss 7.401,Val loss 7.586\n","Epoch 4 (Step 000040): Train loss 7.303,Val loss 7.506\n","Epoch 4 (Step 000041): Train loss 7.257,Val loss 7.433\n","Epoch 4 (Step 000042): Train loss 7.134,Val loss 7.355\n","Epoch 4 (Step 000043): Train loss 7.101,Val loss 7.281\n","Epoch 4 (Step 000044): Train loss 6.995,Val loss 7.218\n","Epoch 4 (Step 000045): Train loss 6.909,Val loss 7.152\n","Epoch 4 (Step 000046): Train loss 6.830,Val loss 7.077\n","Epoch 4 (Step 000047): Train loss 6.784,Val loss 7.009\n","Epoch 4 (Step 000048): Train loss 6.681,Val loss 6.951\n","Epoch 4 (Step 000049): Train loss 6.642,Val loss 6.910\n","Epoch 4 (Step 000050): Train loss 6.499,Val loss 6.863\n","Epoch 4 (Step 000051): Train loss 6.498,Val loss 6.833\n","Once upon a time, and I, and the I, and the I, and I, and the”                                \n","Epoch 5 (Step 000052): Train loss 6.409,Val loss 6.784\n","Epoch 5 (Step 000053): Train loss 6.390,Val loss 6.751\n","Epoch 5 (Step 000054): Train loss 6.308,Val loss 6.749\n","Epoch 5 (Step 000055): Train loss 6.252,Val loss 6.694\n","Epoch 5 (Step 000056): Train loss 6.136,Val loss 6.657\n","Epoch 5 (Step 000057): Train loss 6.102,Val loss 6.659\n","Epoch 5 (Step 000058): Train loss 6.005,Val loss 6.609\n","Epoch 5 (Step 000059): Train loss 6.002,Val loss 6.579\n","Epoch 5 (Step 000060): Train loss 6.000,Val loss 6.605\n","Epoch 5 (Step 000061): Train loss 6.022,Val loss 6.576\n","Epoch 5 (Step 000062): Train loss 5.901,Val loss 6.558\n","Epoch 5 (Step 000063): Train loss 5.838,Val loss 6.538\n","Epoch 5 (Step 000064): Train loss 5.727,Val loss 6.514\n","Once upon a time, and I was a little of the sea, and the sea.                                     \n","Epoch 6 (Step 000065): Train loss 5.771,Val loss 6.540\n","Epoch 6 (Step 000066): Train loss 5.709,Val loss 6.496\n","Epoch 6 (Step 000067): Train loss 5.634,Val loss 6.480\n","Epoch 6 (Step 000068): Train loss 5.612,Val loss 6.546\n","Epoch 6 (Step 000069): Train loss 5.679,Val loss 6.479\n","Epoch 6 (Step 000070): Train loss 5.679,Val loss 6.468\n","Epoch 6 (Step 000071): Train loss 5.518,Val loss 6.461\n","Epoch 6 (Step 000072): Train loss 5.466,Val loss 6.482\n","Epoch 6 (Step 000073): Train loss 5.397,Val loss 6.477\n","Epoch 6 (Step 000074): Train loss 5.315,Val loss 6.460\n","Epoch 6 (Step 000075): Train loss 5.395,Val loss 6.445\n","Epoch 6 (Step 000076): Train loss 5.240,Val loss 6.426\n","Epoch 6 (Step 000077): Train loss 5.205,Val loss 6.441\n","Once upon a time, and a little, and a little, and a little, and a man of the sea, and then, and a little, and a little he was a man of the sea-e, and the sea-e of the sea-e of\n","Epoch 7 (Step 000078): Train loss 5.055,Val loss 6.418\n","Epoch 7 (Step 000079): Train loss 5.070,Val loss 6.448\n","Epoch 7 (Step 000080): Train loss 5.099,Val loss 6.454\n","Epoch 7 (Step 000081): Train loss 5.020,Val loss 6.433\n","Epoch 7 (Step 000082): Train loss 5.041,Val loss 6.432\n","Epoch 7 (Step 000083): Train loss 4.952,Val loss 6.436\n","Epoch 7 (Step 000084): Train loss 4.931,Val loss 6.426\n","Epoch 7 (Step 000085): Train loss 4.815,Val loss 6.442\n","Epoch 7 (Step 000086): Train loss 4.822,Val loss 6.431\n","Epoch 7 (Step 000087): Train loss 4.757,Val loss 6.425\n","Epoch 7 (Step 000088): Train loss 4.748,Val loss 6.428\n","Epoch 7 (Step 000089): Train loss 4.710,Val loss 6.393\n","Epoch 7 (Step 000090): Train loss 4.647,Val loss 6.428\n","Once upon a time, and I thought I had been a little and the same of a little in the same.                          “The a the bed\n","Epoch 8 (Step 000091): Train loss 4.560,Val loss 6.408\n","Epoch 8 (Step 000092): Train loss 4.545,Val loss 6.385\n","Epoch 8 (Step 000093): Train loss 4.489,Val loss 6.448\n","Epoch 8 (Step 000094): Train loss 4.517,Val loss 6.395\n","Epoch 8 (Step 000095): Train loss 4.352,Val loss 6.422\n","Epoch 8 (Step 000096): Train loss 4.313,Val loss 6.427\n","Epoch 8 (Step 000097): Train loss 4.259,Val loss 6.419\n","Epoch 8 (Step 000098): Train loss 4.258,Val loss 6.445\n","Epoch 8 (Step 000099): Train loss 4.213,Val loss 6.384\n","Epoch 8 (Step 000100): Train loss 4.142,Val loss 6.412\n","Epoch 8 (Step 000101): Train loss 4.102,Val loss 6.397\n","Epoch 8 (Step 000102): Train loss 4.112,Val loss 6.404\n","Epoch 8 (Step 000103): Train loss 4.071,Val loss 6.396\n","Once upon a time, and I had a little and I had a little and I had a good, I had a good could not a good, and I had been a good, and I thought I had a good in the bed, and in the sea, and I\n","Epoch 9 (Step 000104): Train loss 3.907,Val loss 6.417\n","Epoch 9 (Step 000105): Train loss 4.021,Val loss 6.426\n","Epoch 9 (Step 000106): Train loss 3.913,Val loss 6.423\n","Epoch 9 (Step 000107): Train loss 3.871,Val loss 6.419\n","Epoch 9 (Step 000108): Train loss 3.799,Val loss 6.406\n","Epoch 9 (Step 000109): Train loss 3.727,Val loss 6.426\n","Epoch 9 (Step 000110): Train loss 3.787,Val loss 6.431\n","Epoch 9 (Step 000111): Train loss 3.763,Val loss 6.481\n","Epoch 9 (Step 000112): Train loss 3.620,Val loss 6.449\n","Epoch 9 (Step 000113): Train loss 3.590,Val loss 6.465\n","Epoch 9 (Step 000114): Train loss 3.600,Val loss 6.449\n","Epoch 9 (Step 000115): Train loss 3.539,Val loss 6.460\n","Epoch 9 (Step 000116): Train loss 3.542,Val loss 6.506\n","Once upon a time, or other—a whaleman the room, and the room.      “Landlord, the whaling, the whaleman of the Captain, the sea-e!’s the harpooneer\n","Epoch 10 (Step 000117): Train loss 3.484,Val loss 6.426\n","Epoch 10 (Step 000118): Train loss 3.384,Val loss 6.450\n","Epoch 10 (Step 000119): Train loss 3.275,Val loss 6.409\n","Epoch 10 (Step 000120): Train loss 3.301,Val loss 6.438\n","Epoch 10 (Step 000121): Train loss 3.269,Val loss 6.483\n","Epoch 10 (Step 000122): Train loss 3.181,Val loss 6.487\n","Epoch 10 (Step 000123): Train loss 3.235,Val loss 6.486\n","Epoch 10 (Step 000124): Train loss 3.111,Val loss 6.505\n","Epoch 10 (Step 000125): Train loss 3.094,Val loss 6.450\n","Epoch 10 (Step 000126): Train loss 3.050,Val loss 6.479\n","Epoch 10 (Step 000127): Train loss 2.960,Val loss 6.472\n","Epoch 10 (Step 000128): Train loss 2.936,Val loss 6.471\n","Epoch 10 (Step 000129): Train loss 2.876,Val loss 6.476\n","Once upon a time, I could not a little in the time, that is a little and in a few of a good thing; and then, and all, I could not the sea, and the great tempest was only by the sea as if it were the great\n","Epoch 11 (Step 000130): Train loss 2.829,Val loss 6.500\n","Epoch 11 (Step 000131): Train loss 2.808,Val loss 6.531\n","Epoch 11 (Step 000132): Train loss 2.867,Val loss 6.570\n","Epoch 11 (Step 000133): Train loss 2.759,Val loss 6.579\n","Epoch 11 (Step 000134): Train loss 2.785,Val loss 6.550\n","Epoch 11 (Step 000135): Train loss 2.737,Val loss 6.574\n","Epoch 11 (Step 000136): Train loss 2.706,Val loss 6.549\n","Epoch 11 (Step 000137): Train loss 2.684,Val loss 6.556\n","Epoch 11 (Step 000138): Train loss 2.533,Val loss 6.626\n","Epoch 11 (Step 000139): Train loss 2.510,Val loss 6.568\n","Epoch 11 (Step 000140): Train loss 2.514,Val loss 6.590\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4141964413.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mstart_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Once upon a time,\"\u001b[0m \u001b[0;31m# Replace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m train_losses, val_losses, tokens_seen = training_loop(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2903774959.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer, config, scheduler, ckpt_dir, ckpt_freq, resume_path)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mckpt_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mckpt_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"ckpt_step_{global_step:06d}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtokens_seen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# number of elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-933810241.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(path, model, optimizer, scheduler, my_config, global_step, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     torch.save({\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                     \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m                     \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;34m\"\"\"Return a CPU copy of this storage if it's not already on the CPU.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["generate_and_print_sample(model_2, tokenizer, config[\"device\"], \"Once upon a time,\",\n","                          temperature=1, top_k=3, eos_id=50256)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K99wtPKgaUcw","executionInfo":{"status":"ok","timestamp":1768426159094,"user_tz":300,"elapsed":1125,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"fb28437a-9f1d-41cc-b616-105fb4815fbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time, and I could not to be it were this harpooneer is, and there was now. I have been still more; and for a few minutes more than that his head to make me that the bed, and for the harpooneer\n"]}]},{"cell_type":"markdown","source":["**Optional Exercise:**\n","Load OpenAI pretrained weights into GPT and perform classification on the spam dataset from an earlier lecture while utilizing LoRA."],"metadata":{"id":"KkKrt2mchp1D"}},{"cell_type":"code","source":["import urllib.request\n","url = (\n","    \"https://raw.githubusercontent.com/rasbt/\"\n","    \"LLMs-from-scratch/main/ch05/\"\n","    \"01_main-chapter-code/gpt_download.py\"\n",")\n","filename = url.split(\"/\")[-1]\n","urllib.request.urlretrieve(url, filename)"],"metadata":{"id":"KGIS4c_3ijb-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768426183682,"user_tz":300,"elapsed":120,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"54d2be2e-a680-480c-c300-e3af9dbf0191"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('gpt_download.py', <http.client.HTTPMessage at 0x79888f01da30>)"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","settings, params = download_and_load_gpt2(\n","    model_size=\"124M\", models_dir=\"gpt2\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qg4fVD-qaido","executionInfo":{"status":"ok","timestamp":1768426245487,"user_tz":300,"elapsed":48302,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"38b2b73a-6a17-4cc1-9478-b8dc1d258f4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 163kiB/s]\n","encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.57MiB/s]\n","hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 242kiB/s]\n","model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:36<00:00, 13.6MiB/s]\n","model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 11.8MiB/s]\n","model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.13MiB/s]\n","vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.45MiB/s]\n"]}]},{"cell_type":"code","source":["print(\"Settings:\", settings)\n","print(\"Parameter dictionary keys:\", params.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kia9crQ_a0k7","executionInfo":{"status":"ok","timestamp":1768426269211,"user_tz":300,"elapsed":45,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"920145d9-1662-47e0-d000-123a28f3d5ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n","Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"]}]},{"cell_type":"code","source":["def assign(left, right):\n","    if left.shape != right.shape:\n","        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n","                         f\"Right: {right.shape}\")\n","    return torch.nn.Parameter(torch.tensor(right))\n","\n","import numpy as np\n","\n","def load_weights_into_gpt(gpt, params):\n","    gpt.position_embedding.weight = assign(gpt.position_embedding.weight, params['wpe'])\n","    gpt.token_embedding.weight = assign(gpt.token_embedding.weight, params['wte'])\n","\n","    for b in range(len(params[\"blocks\"])):\n","        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n","        if gpt.blocks[b].attn.W_query.__class__.__name__ == \"LoRALinear\":\n","            W_q = gpt.blocks[b].attn.W_query.linear\n","            W_k = gpt.blocks[b].attn.W_key.linear\n","            W_v = gpt.blocks[b].attn.W_value.linear\n","            att_proj = gpt.blocks[b].attn.projection.linear\n","        else:\n","            W_q = gpt.blocks[b].attn.W_query\n","            W_k = gpt.blocks[b].attn.W_key\n","            W_v = gpt.blocks[b].attn.W_value\n","            att_proj = gpt.blocks[b].attn.projection\n","\n","        W_q.weight = assign(W_q.weight, q_w.T)\n","        W_k.weight = assign(W_k.weight, k_w.T)\n","        W_v.weight = assign(W_v.weight, v_w.T)\n","\n","        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n","        W_q.bias = assign(W_q.bias, q_b)\n","        W_k.bias = assign(W_k.bias, k_b)\n","        W_v.bias = assign(W_v.bias, v_b)\n","\n","        att_proj.weight = assign(att_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n","        att_proj.bias = assign(att_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n","\n","        if gpt.blocks[b].ff.linear1.__class__.__name__ == \"LoRALinear\":\n","            l1 = gpt.blocks[b].ff.linear1.linear\n","            l2 = gpt.blocks[b].ff.linear2.linear\n","        else:\n","            l1 = gpt.blocks[b].ff.linear1\n","            l2 = gpt.blocks[b].ff.linear2\n","\n","        l1.weight = assign(l1.weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n","        l1.bias = assign(l1.bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n","        l2.weight = assign(l2.weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n","        l2.bias = assign(l2.bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n","\n","        gpt.blocks[b].ln1.gamma = assign(gpt.blocks[b].ln1.gamma, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n","        gpt.blocks[b].ln1.beta = assign(gpt.blocks[b].ln1.beta, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n","        gpt.blocks[b].ln2.gamma = assign(gpt.blocks[b].ln2.gamma, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n","        gpt.blocks[b].ln2.beta = assign(gpt.blocks[b].ln2.beta, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n","\n","    gpt.ln_f.gamma = assign(gpt.ln_f.gamma, params[\"g\"])\n","    gpt.ln_f.beta = assign(gpt.ln_f.beta, params[\"b\"])\n","    gpt.prediction_layer.weight = assign(gpt.prediction_layer.weight, params[\"wte\"])\n"],"metadata":{"id":"7RuSYyhea7Hc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We always need a specific dataset in order to fine-tune\n","# The dataset must be relevant to our task\n","# For example:\n","# Dataset where each datapoint is:\n","# (input: text, ground truth: yes/no)\n","import urllib.request\n","import zipfile\n","import os\n","from pathlib import Path\n","\n","url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n","zip_path = \"spam_collection.zip\"\n","extracted_path = \"spam_collection\"\n","data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n","\n","def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n","    if data_file_path.exists():\n","        print(f\"{data_file_path} already exists.\")\n","        return\n","    with urllib.request.urlopen(url) as response:\n","        with open(zip_path, \"wb\") as out_file:\n","            out_file.write(response.read())\n","\n","    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n","        zip_ref.extractall(extracted_path)\n","\n","    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n","    os.rename(original_file_path, data_file_path)\n","\n","    print(f\"Data downloaded and extracted to {extracted_path}.\")\n","\n","download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38f_vUlvbJdI","executionInfo":{"status":"ok","timestamp":1768426348539,"user_tz":300,"elapsed":594,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"0a69995f-9b63-44d7-af88-3731e3764483"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data downloaded and extracted to spam_collection.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n","# df.columns = [\"label\", \"text\"]\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"IJblwocDbKan","executionInfo":{"status":"ok","timestamp":1768426357741,"user_tz":300,"elapsed":104,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"b6704367-e9f7-419b-c09d-285b1f9cd689"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Label                                               Text\n","0      ham  Go until jurong point, crazy.. Available only ...\n","1      ham                      Ok lar... Joking wif u oni...\n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      ham  U dun say so early hor... U c already then say...\n","4      ham  Nah I don't think he goes to usf, he lives aro...\n","...    ...                                                ...\n","5567  spam  This is the 2nd time we have tried 2 contact u...\n","5568   ham               Will ü b going to esplanade fr home?\n","5569   ham  Pity, * was in mood for that. So...any other s...\n","5570   ham  The guy did some bitching but I acted like i'd...\n","5571   ham                         Rofl. Its true to its name\n","\n","[5572 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-9e1be900-b7a2-4268-8140-49533eb1a55a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>spam</td>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>ham</td>\n","      <td>Will ü b going to esplanade fr home?</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>ham</td>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>ham</td>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>ham</td>\n","      <td>Rofl. Its true to its name</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e1be900-b7a2-4268-8140-49533eb1a55a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9e1be900-b7a2-4268-8140-49533eb1a55a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9e1be900-b7a2-4268-8140-49533eb1a55a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_22d5154e-8400-4e55-87a7-eefa9574141e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_22d5154e-8400-4e55-87a7-eefa9574141e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["def create_balanced_spam_dataset(df):\n","    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n","    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n","        num_spam, random_state=123\n","    )\n","    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n","    return balanced_df\n","\n","balanced_df = create_balanced_spam_dataset(df)\n","print(balanced_df[\"Label\"].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bWvipzebNO0","executionInfo":{"status":"ok","timestamp":1768426370193,"user_tz":300,"elapsed":25,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"97f39e48-6db9-42de-8fd0-44233a75ad77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label\n","ham     747\n","spam    747\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"],"metadata":{"id":"G58OPnvEbP3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from operator import index\n","# Split dataset into train, validation, test\n","\n","def random_split(df, train_ratio=0.8, val_ratio=0.1):\n","    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n","    train_end = int(train_ratio * len(df))\n","    val_end = train_end + int(val_ratio * len(df))\n","\n","    train_df = df[:train_end]\n","    val_df = df[train_end:val_end] # Includes train_end but not val_end\n","    test_df = df[val_end:]\n","\n","    return train_df, val_df, test_df"],"metadata":{"id":"UikW_sXbbS_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, val_df, test_df = random_split(balanced_df)\n","train_df.to_csv(\"train.csv\", index=None)\n","val_df.to_csv(\"val.csv\", index=None)\n","test_df.to_csv(\"test.csv\", index=None)"],"metadata":{"id":"kb2xP6R5bUuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SpamDataset(Dataset):\n","    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n","        self.data = pd.read_csv(csv_file)\n","         # TODO: Tokenize the text\n","        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n","\n","        if max_length is None:\n","            self.max_length = self._longest_encoded_length()\n","        else:\n","            self.max_length = max_length\n","            # TODO: Truncate the text\n","            self.encoded_texts = [encoded_text[:self.max_length]\n","                                  for encoded_text in self.encoded_texts]\n","\n","        # TODO: Pad the text\n","        self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n","                              for encoded_text in self.encoded_texts]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        encoded_text = torch.tensor(self.encoded_texts[idx], dtype=torch.long)\n","        label = torch.tensor(self.data.iloc[idx][\"Label\"], dtype=torch.long)\n","        return encoded_text, label\n","\n","    def _longest_encoded_length(self):\n","        return max(len(encoded_text) for encoded_text in self.encoded_texts)"],"metadata":{"id":"IbzaDrpdbW3d","executionInfo":{"status":"error","timestamp":1768509784499,"user_tz":300,"elapsed":19,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"4cdb0712-3197-463c-93f1-1aaba1ab5afe","colab":{"base_uri":"https://localhost:8080/","height":211}},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3886154770.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSpamDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0;31m# TODO: Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoded_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"]}]},{"cell_type":"code","source":["tokenizer = tiktoken.get_encoding(\"gpt2\")\n","max_length = None\n","train_dataset = SpamDataset(csv_file=\"train.csv\", tokenizer=tokenizer, max_length=max_length)\n","val_dataset = SpamDataset(csv_file=\"val.csv\", tokenizer=tokenizer, max_length=max_length)\n","test_dataset = SpamDataset(csv_file=\"test.csv\", tokenizer=tokenizer, max_length=max_length)"],"metadata":{"id":"IcjdSW3WbaID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_workers = 0\n","batch_size = 8\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"],"metadata":{"id":"3XNH5b-UbcMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["settings, params = download_and_load_gpt2(\n","    model_size=\"124M\", models_dir=\"gpt2\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0V6uqHxNbeDF","executionInfo":{"status":"ok","timestamp":1768426444175,"user_tz":300,"elapsed":1715,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"ab4d64b2-2045-456b-9add-43157c8e3a62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File already exists and is up-to-date: gpt2/124M/checkpoint\n","File already exists and is up-to-date: gpt2/124M/encoder.json\n","File already exists and is up-to-date: gpt2/124M/hparams.json\n","File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n","File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n","File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n","File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"]}]},{"cell_type":"code","source":["\n","\n","spam_model_name = \"gpt2-small (124M)\"\n","# spam_model_name = \"gpt2-medium (355M)\"\n","# spam_model_name = \"gpt2-large (774M)\"\n","# spam_model_name = \"gpt2-xl (1558M)\"\n","SPAM_CONFIG = config_format.copy()\n","SPAM_CONFIG.update(model_configs[spam_model_name])\n","SPAM_CONFIG.update({\"context_length\": 1024})\n","SPAM_CONFIG.update({\"qkv_bias\": True})\n","SPAM_CONFIG.update({\"use_lora\": True})\n","SPAM_CONFIG.update({\"lora_targets\": [\"attn\", \"ff\"]})\n","\n","\n","spam_model = Simple_GPT(SPAM_CONFIG)\n","load_weights_into_gpt(spam_model, params)\n","spam_model.to(device)\n","\n","spam_optimizer = create_optimizer(spam_model, config)\n","spam_scheduler = create_scheduler(optimizer, config)\n","\n","SPAM_CONFIG"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LezQ6mNMbh8T","executionInfo":{"status":"ok","timestamp":1768427466859,"user_tz":300,"elapsed":1514,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"c2a3b632-585a-43f7-9168-64897a946527"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'vocab_size': 50257,\n"," 'context_length': 1024,\n"," 'n_embd': 768,\n"," 'n_heads': 12,\n"," 'n_layers': 12,\n"," 'dropout_rate': 0.1,\n"," 'qkv_bias': True,\n"," 'norm_type': 'layernorm',\n"," 'lr': 0.0004,\n"," 'weight_decay': 0.1,\n"," 'betas': (0.9, 0.95),\n"," 'grad_clip_norm': 1.0,\n"," 'warmup_steps': 200,\n"," 'total_steps': 2000,\n"," 'ckpt_dir': 'checkpoints',\n"," 'ckpt_every': 500,\n"," 'resume': False,\n"," 'resume_path': None,\n"," 'temperature': 1.0,\n"," 'use_lora': True,\n"," 'lora_r': 8,\n"," 'lora_alpha': 16,\n"," 'lora_dropout': 0.0,\n"," 'lora_targets': ['attn', 'ff'],\n"," 'device': 'cuda'}"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["num_classes = 2\n","spam_model.prediction_layer = nn.Linear(SPAM_CONFIG[\"n_embd\"], num_classes)\n","spam_model.to(SPAM_CONFIG[\"device\"])\n","0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWJbg3Z3epCf","executionInfo":{"status":"ok","timestamp":1768427469573,"user_tz":300,"elapsed":13,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"07cb5623-a515-426e-d923-5066c43b4d1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["def calculate_spam_accuracy(model, dataloader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for input_batch, target_batch in dataloader:\n","            # TODO: Move input and target batch to proper device\n","            input_batch = input_batch.to(device)\n","            target_batch = target_batch.to(device)\n","\n","            # TODO: Obtain logits\n","            logits = model(input_batch) # B x N x 2, where 2 is # classes\n","\n","            # TODO: Get last token from each context window\n","            last_logits = logits[:, -1, :] # B x 2\n","\n","            # TODO: Use argmax to get predicted labels\n","            predicted_labels = torch.argmax(last_logits, dim=-1)\n","\n","            total += predicted_labels.shape[0] # total += Batch size\n","            correct += (predicted_labels == target_batch).sum().item()\n","    accuracy = correct / total\n","    return accuracy"],"metadata":{"id":"gU54w7Xsey7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_accuracy = calculate_spam_accuracy(spam_model, train_dataloader, device)\n","val_accuracy = calculate_spam_accuracy(spam_model, val_dataloader, device)\n","test_accuracy = calculate_spam_accuracy(spam_model, test_dataloader, device)\n","print(f\"Train accuracy: {train_accuracy}\")\n","print(f\"Val accuracy: {val_accuracy}\")\n","print(f\"Test accuracy: {test_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0LbU_AbfAXq","executionInfo":{"status":"ok","timestamp":1768427369943,"user_tz":300,"elapsed":4099,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"5f781a39-8858-4733-a578-a3e6b5843c15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train accuracy: 0.499581589958159\n","Val accuracy: 0.47651006711409394\n","Test accuracy: 0.5266666666666666\n"]}]},{"cell_type":"code","source":["# Calculate the loss for a single batch\n","def calculate_spam_loss_batch(input_batch, target_batch, model, device):\n","    # TODO: Move batches to the proper device\n","    input_batch = input_batch.to(device)\n","    target_batch = target_batch.to(device)\n","\n","    # TODO: Obtain logits\n","    logits = model(input_batch)[:, -1, :]\n","    # Unlike our original training, we only want the last token in each context window\n","    # Originally: Predict next token -> correctly predicting earlier tokens is some measure\n","    # of model's performance\n","    # Now: Binary classification -> only care about the final classification\n","    # We don't care about classifications with incomplete information\n","\n","    # TODO: Calculate loss\n","    loss = nn.functional.cross_entropy(logits, target_batch)\n","    return loss\n","\n","# Calculate overall spam loss\n","def calculate_spam_loss(model, dataloader, device):\n","    total_loss = 0.0\n","    total_tokens = 0\n","    if len(dataloader) == 0:\n","        return float(\"nan\")\n","\n","    for input_batch, target_batch in dataloader:\n","        # TODO: Calculate batch loss\n","        loss = calculate_spam_loss_batch(input_batch, target_batch, model, device)\n","\n","        # TODO: Update total_loss\n","        total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)\n","\n"],"metadata":{"id":"MoxD2O4bfEAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_spam_classifier(model, train_dataloader, val_dataloader,\n","                          optimizer, device, num_epochs, eval_freq=50, eval_iter=5):\n","    train_losses = []\n","    val_losses = []\n","    train_accs = []\n","    val_accs = []\n","\n","    examples_seen, global_step = 0, -1\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for input_batch, target_batch in train_dataloader:\n","            # TODO: Perform one parameter update\n","            # (you can use last lecture's training loop as reference)\n","            optimizer.zero_grad()\n","            loss = calculate_spam_loss_batch(input_batch, target_batch, model, device)\n","            loss.backward()\n","            optimizer.step()\n","\n","            global_step += 1\n","            examples_seen += input_batch.shape[0] # batch size\n","\n","            if global_step % eval_freq == 0:\n","                with torch.no_grad():\n","                    train_loss = calculate_spam_loss(model, train_dataloader, device)\n","                    val_loss = calculate_spam_loss(model, val_dataloader, device)\n","                train_losses.append(train_loss)\n","                val_losses.append(val_loss)\n","\n","                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f},\"\n","                      f\"Val loss {val_loss:.3f}\")\n","\n","        train_acc = calculate_spam_accuracy(model, train_dataloader, device)\n","        val_acc = calculate_spam_accuracy(model, val_dataloader, device)\n","        train_accs.append(train_acc)\n","        val_accs.append(val_acc)\n","        print(f\"Train accuracy: {train_acc}\")\n","        print(f\"Val accuracy: {val_acc}\")\n","\n","    return train_losses, val_losses, train_accs, val_accs"],"metadata":{"id":"j6oJuj6LfilR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spam_optimizer = torch.optim.AdamW(spam_model.parameters(), lr=5e-5, weight_decay=0.1)\n","num_epochs = 5\n","\n","train_losses, val_losses, train_accs, val_accs = train_spam_classifier(\n","    spam_model, train_dataloader, val_dataloader,\n","    spam_optimizer, device, num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLLmHAUAfKw0","executionInfo":{"status":"ok","timestamp":1768427680052,"user_tz":300,"elapsed":145509,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"bb32241c-a3d5-4a50-edbc-23e61fa43f3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 (Step 000000): Train loss 1.928,Val loss 2.333\n","Epoch 1 (Step 000050): Train loss 0.479,Val loss 0.406\n","Epoch 1 (Step 000100): Train loss 0.501,Val loss 0.456\n","Train accuracy: 0.9405857740585774\n","Val accuracy: 0.9664429530201343\n","Epoch 2 (Step 000150): Train loss 0.196,Val loss 0.158\n","Epoch 2 (Step 000200): Train loss 0.223,Val loss 0.178\n","Epoch 2 (Step 000250): Train loss 0.134,Val loss 0.107\n","Train accuracy: 0.9790794979079498\n","Val accuracy: 0.9731543624161074\n","Epoch 3 (Step 000300): Train loss 0.078,Val loss 0.066\n","Epoch 3 (Step 000350): Train loss 0.098,Val loss 0.113\n","Epoch 3 (Step 000400): Train loss 0.070,Val loss 0.108\n","Train accuracy: 0.9849372384937238\n","Val accuracy: 0.959731543624161\n","Epoch 4 (Step 000450): Train loss 0.056,Val loss 0.102\n","Epoch 4 (Step 000500): Train loss 0.057,Val loss 0.141\n","Epoch 4 (Step 000550): Train loss 0.071,Val loss 0.115\n","Train accuracy: 0.9924686192468619\n","Val accuracy: 0.9798657718120806\n","Epoch 5 (Step 000600): Train loss 0.027,Val loss 0.096\n","Epoch 5 (Step 000650): Train loss 0.114,Val loss 0.213\n","Epoch 5 (Step 000700): Train loss 0.051,Val loss 0.145\n","Train accuracy: 0.998326359832636\n","Val accuracy: 0.9798657718120806\n"]}]},{"cell_type":"code","source":["calculate_spam_accuracy(spam_model, test_dataloader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GsjGqNegRe1","executionInfo":{"status":"ok","timestamp":1768427692335,"user_tz":300,"elapsed":460,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"e64c7d54-1eba-4dbb-9197-669b3388d6a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9666666666666667"]},"metadata":{},"execution_count":150}]},{"cell_type":"code","source":["def classify_spam_text(text, model, tokenizer, device, max_length=None,\n","                       pad_token_id=50256):\n","    model.eval()\n","    with torch.no_grad():\n","        input_ids = tokenizer.encode(text)\n","        supported_context_length = model.config[\"context_length\"]\n","        if max_length is None:\n","            max_length = supported_context_length\n","        input_ids = input_ids[:min(max_length, supported_context_length)]\n","        input_ids += [pad_token_id] * (max_length - len(input_ids))\n","\n","        input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)\n","        logits = model(input_tensor)[:, -1, :]\n","        predicted_label = torch.argmax(logits, dim=-1).item()\n","    return (\"spam\" if predicted_label == 1 else \"not spam\", torch.softmax(logits, dim=-1))"],"metadata":{"id":"YLajhHf6gWYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_text_1 = \"You are a winner you have been specially selected to receive $1000\"\n","sample_text_2 = \"Are you coming home tonight\"\n","sample_text_3 = \"\"\"\n","Pennsylvania (DMV) Final Notice: Enforcement Begins August 6nd. \\\n","Our records indicate that as of today, you still have an outstanding traffic ticket.\n","\"\"\"\n","sample_text_4 = \"MIT Alert: Gas leak in Building 46. Responders on scene. Vassar Street closed.\"\n","for text in [sample_text_1, sample_text_2, sample_text_3, sample_text_4]:\n","    print(classify_spam_text(text, spam_model, tokenizer, device,\n","                         max_length=train_dataset.max_length))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcxgqUN2gZBA","executionInfo":{"status":"ok","timestamp":1768427722590,"user_tz":300,"elapsed":97,"user":{"displayName":"Daniel Li","userId":"13094439128691031074"}},"outputId":"27cfb80d-e903-4cd2-a306-efcfd1298985"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('spam', tensor([[1.1339e-04, 9.9989e-01]], device='cuda:0'))\n","('not spam', tensor([[9.9971e-01, 2.9122e-04]], device='cuda:0'))\n","('not spam', tensor([[0.8583, 0.1417]], device='cuda:0'))\n","('not spam', tensor([[0.5905, 0.4095]], device='cuda:0'))\n"]}]}]}