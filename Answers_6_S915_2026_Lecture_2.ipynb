{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Concept Questions"
      ],
      "metadata": {
        "id": "oPZNCPGWP7lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the dot product between vectors `<1, 2, 3>` and `<4, 5, 6>`?\n",
        "2. Given information about sizes of matrices `A` and `B`, find the size of `A @ B` if it exists.\n",
        "\n",
        "    a. `A` is 8x5 and `B` is 5x7\n",
        "\n",
        "    b. `A` is 8x6 and `B` is 3x4\n",
        "\n",
        "    c. `A` is 8x8 and `B` is 2x8\n",
        "\n",
        "    d. `A` is 2x8 and `B` is 8x8\n",
        "\n",
        "    e. `A` is 4x6 and `B.T` is 4x6\n",
        "\n",
        "3. True or False:\n",
        "\n",
        "    a. Queries are only matched to one key.\n",
        "\n",
        "    b. Query, Key, and Value vectors have the same size.\n",
        "\n",
        "    c. We can obtain Q, K, and V matrices by multiplying an input matrix by trainable matrices.\n",
        "\n",
        "4. What does $QK^T$ represent?\n",
        "\n",
        "5. Explain the role of `__init__` and `forward` in a machine learning Module."
      ],
      "metadata": {
        "id": "LbBgMvACP93-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 1 * 4 + 2 * 5 + 3 * 6 = 32\n",
        "2.\n",
        "\n",
        "  a. 8x7\n",
        "\n",
        "  b. Doesn't exist since 6 is different from 3\n",
        "\n",
        "  c. Doesn't exist since 8 is different from 2\n",
        "\n",
        "  d. 2x8\n",
        "\n",
        "  e. Note that B.T being 4x6 means B is 6x4, which makes A@B 4x4\n",
        "\n",
        "3.\n",
        "\n",
        "  a. False. Each query is matched to every key in the context window.\n",
        "\n",
        "  b. True.\n",
        "\n",
        "  c. True.\n",
        "\n",
        "4. Represents similarity scores between all pairs of query and key vectors. It allows tokens to communicate with each other.\n",
        "\n",
        "5.\n",
        "  `__init__` is used to initialize all parameters of a model and initializes other things that can be used later on.\n",
        "\n",
        "  `forward` is used to obtain output from a machine learning model. We feed an input into `forward`, and the forward utilizes the parameters initialized in `__init__` to calculate an output.\n"
      ],
      "metadata": {
        "id": "9d_5UP-eeELJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "9eu7zlxiP5Gx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XZUQimpokTL_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication with Tensors:"
      ],
      "metadata": {
        "id": "zhuYMhTBXHa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2, 3], [4, 5, 6]]) # 2x3 tensor\n",
        "b = torch.tensor([[3], [4], [1]]) # 3x1 tensor\n",
        "c = a @ b # 2x1 tensor\n",
        "print(c)\n",
        "\n",
        "d = torch.zeros(40, 75)\n",
        "e = torch.zeros(75, 25)\n",
        "f = d @ e # 40x25\n",
        "print(f.shape)\n",
        "\n",
        "g = torch.zeros(25, 83)\n",
        "h = d @ e @ g\n",
        "print(h.shape)\n",
        "\n",
        "m1 = torch.zeros(35, 50)\n",
        "m2 = torch.zeros(35, 50)\n",
        "m3 = m1 @ m2.T\n",
        "print(m3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVAs2GCdxnAi",
        "outputId": "bd7d0e31-3dd8-48c1-91b1-8eebfb8a09b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14],\n",
            "        [38]])\n",
            "torch.Size([40, 25])\n",
            "torch.Size([40, 83])\n",
            "torch.Size([35, 35])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.randn(4, 5))\n",
        "print(torch.rand(4, 5))\n",
        "# We want torch.randn because we want negative numbers\n",
        "# If we restrict to positive or use something like torch.zeros, then\n",
        "# the result could be biased towards certain types of data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rOUCkOA61tc",
        "outputId": "84f6f63b-f9d4-4636-c0ba-c84d7ebe927a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0720e+00,  1.5026e+00, -8.1899e-01,  2.6860e-01, -9.4053e-01],\n",
            "        [-4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01, -1.4078e-02],\n",
            "        [-2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01, -1.5822e-03],\n",
            "        [ 1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00, -2.1595e+00]])\n",
            "tensor([[0.6397, 0.8954, 0.2979, 0.6314, 0.5028],\n",
            "        [0.1239, 0.3786, 0.1661, 0.7211, 0.5449],\n",
            "        [0.5490, 0.3483, 0.5024, 0.3445, 0.6437],\n",
            "        [0.9856, 0.5757, 0.2785, 0.1946, 0.5382]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[0.43,0.15,0.89],\n",
        "                        [0.55,0.87,0.66],\n",
        "                        [0.57,0.85,0.64],\n",
        "                        [0.22,0.58,0.33],\n",
        "                        [0.77,0.25,0.10],\n",
        "                        [0.05,0.80,0.55]])\n",
        "n = X.shape[0] # 6\n",
        "d_in = X.shape[1] # 3\n",
        "d_out = 2\n",
        "torch.manual_seed(123)\n",
        "\n",
        "W_q = nn.Parameter(torch.randn(d_in, d_out))\n",
        "W_k = nn.Parameter(torch.randn(d_in, d_out))\n",
        "W_v = nn.Parameter(torch.randn(d_in, d_out))\n",
        "\n",
        "# X is n x d_in\n",
        "# W_q is d_in x d_out\n",
        "# X @ W_q is n x d_out\n",
        "\n",
        "Q = X @ W_q # n x d_out\n",
        "K = X @ W_k # n x d_out\n",
        "V = X @ W_v # n x d_out\n",
        "print(Q)\n",
        "print(K)\n",
        "print(V)\n",
        "\n",
        "# Q is n x d_out\n",
        "# K is n x d_out\n",
        "# K.T is d_out x n\n",
        "# Q x K.T is n x n\n",
        "QKT = Q @ K.T\n",
        "print(QKT)\n",
        "\n",
        "A = torch.softmax(QKT / (d_out ** 0.5), dim=1)\n",
        "print(A)\n",
        "print(sum(A[0])) # 1 because softmax ensures that the elements of the vector sum to 1\n",
        "\n",
        "# A is n x n\n",
        "# V is n x d_out\n",
        "# context_vector = n x d_out\n",
        "# actually is a context matrix made up of context vectors of each token\n",
        "context_vector = A @ V\n",
        "print(context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMXu21V3x13R",
        "outputId": "a7453497-50ca-4fdd-a459-5cb2f4e232f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1686,  0.2019],\n",
            "        [-1.1729, -0.0048],\n",
            "        [-1.1438, -0.0018],\n",
            "        [-0.6339, -0.0439],\n",
            "        [-0.2979,  0.0535],\n",
            "        [-0.9596, -0.0712]], grad_fn=<MmBackward0>)\n",
            "tensor([[-0.1823, -0.6888],\n",
            "        [-0.1142, -0.7676],\n",
            "        [-0.1443, -0.7728],\n",
            "        [ 0.0434, -0.3580],\n",
            "        [-0.6467, -0.6476],\n",
            "        [ 0.3262, -0.3395]], grad_fn=<MmBackward0>)\n",
            "tensor([[ 0.1196, -0.3566],\n",
            "        [ 0.4107,  0.6274],\n",
            "        [ 0.4091,  0.6390],\n",
            "        [ 0.2436,  0.4182],\n",
            "        [ 0.2653,  0.6668],\n",
            "        [ 0.2728,  0.3242]], grad_fn=<MmBackward0>)\n",
            "tensor([[ 0.0740, -0.0216,  0.0126, -0.1230,  0.6250, -0.4498],\n",
            "        [ 0.2172,  0.1376,  0.1730, -0.0491,  0.7616, -0.3809],\n",
            "        [ 0.2098,  0.1320,  0.1665, -0.0489,  0.7408, -0.3725],\n",
            "        [ 0.1458,  0.1061,  0.1254, -0.0118,  0.4384, -0.1919],\n",
            "        [ 0.0175, -0.0071,  0.0017, -0.0321,  0.1580, -0.1153],\n",
            "        [ 0.2240,  0.1642,  0.1935, -0.0161,  0.6667, -0.2888]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "tensor([[0.1687, 0.1576, 0.1615, 0.1467, 0.2490, 0.1165],\n",
            "        [0.1704, 0.1611, 0.1652, 0.1412, 0.2505, 0.1117],\n",
            "        [0.1704, 0.1613, 0.1653, 0.1419, 0.2481, 0.1129],\n",
            "        [0.1704, 0.1656, 0.1679, 0.1524, 0.2095, 0.1342],\n",
            "        [0.1680, 0.1651, 0.1661, 0.1622, 0.1856, 0.1529],\n",
            "        [0.1711, 0.1640, 0.1675, 0.1444, 0.2340, 0.1191]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor([[0.2845, 0.4071],\n",
            "        [0.2854, 0.4081],\n",
            "        [0.2854, 0.4075],\n",
            "        [0.2864, 0.3974],\n",
            "        [0.2863, 0.3910],\n",
            "        [0.2860, 0.4039]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1:** Fill out missing or incomplete parts of the following attention module."
      ],
      "metadata": {
        "id": "ItALgQULXdr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionV1(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.d_in = d_in\n",
        "        self.d_out = d_out\n",
        "        self.W_query = nn.Parameter(torch.randn(d_in, d_out))\n",
        "        self.W_key = nn.Parameter(torch.randn(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.randn(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is n x d_in and W_q is d_in x d_out\n",
        "        # Q is n x d_out\n",
        "        Q = x @ W_q\n",
        "        K = x @ W_k\n",
        "        V = x @ W_v\n",
        "        QKT = Q @ K.T\n",
        "        A = torch.softmax(QKT / (self.d_out ** 0.5), dim=1)\n",
        "        context_vector = A @ V\n",
        "        return context_vector"
      ],
      "metadata": {
        "id": "hRw-FuUYz2Dc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the self-attention module:"
      ],
      "metadata": {
        "id": "CHW0CTCnYHfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "# X is 6 x 3\n",
        "self_attention = SelfAttentionV1(d_in=X.shape[1], d_out=2)  # calls __init__\n",
        "context_vector = self_attention(X)  # calls the forward function\n",
        "# self_attention.forward(X)\n",
        "print(context_vector) # 6 x 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY6Xee7A1ic1",
        "outputId": "f970d330-8447-4532-d0d7-66f95dd6f6e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2845, 0.4071],\n",
            "        [0.2854, 0.4081],\n",
            "        [0.2854, 0.4075],\n",
            "        [0.2864, 0.3974],\n",
            "        [0.2863, 0.3910],\n",
            "        [0.2860, 0.4039]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, `nn.Linear` is used instead of `nn.Parameter`."
      ],
      "metadata": {
        "id": "fK3DJx1KYbg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = nn.Linear(10, 20) # This linear layer transforms a vector of size\n",
        "# 10 into a vector of size 20\n",
        "\n",
        "a = torch.zeros(10)\n",
        "b = linear_layer(a) # Shape: 20\n",
        "# linear_layer(a) internally multiplies by a matrix of size 10x20 on the right side\n",
        "# Math-wise, it is matrix multiplication of 1x10 multiplied by 10x20\n",
        "print(b.shape)\n",
        "\n",
        "# Linear also works well with batches\n",
        "c = torch.zeros(8, 10) # Batch size 8; Shape: 8x10\n",
        "d = linear_layer(c) # Shape: 8x20\n",
        "# Multiplies the 8x10 matrix c by a 10x20 parameter matrix\n",
        "# Result is an 8x20 matrix\n",
        "print(d.shape)\n",
        "\n",
        "# Linear works with even more dimensions by only transforming the last layer\n",
        "e = torch.zeros(2, 4, 10)\n",
        "f = linear_layer(e) # Shape: 2x4x20\n",
        "print(f.shape)\n",
        "\n",
        "\n",
        "\n",
        "g = torch.zeros(5, 5, 5, 5, 5, 5, 10)\n",
        "h = linear_layer(g)\n",
        "print(h.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jawEXX1tYfWh",
        "outputId": "29075822-0fe0-43ac-e08c-4de502543c43"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20])\n",
            "torch.Size([8, 20])\n",
            "torch.Size([2, 4, 20])\n",
            "torch.Size([5, 5, 5, 5, 5, 5, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2:** Fill out missing or incomplete parts of the following module while utilizing `nn.Linear`."
      ],
      "metadata": {
        "id": "xnFFaAzkYOwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionV2(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.d_in = d_in\n",
        "        self.d_out = d_out\n",
        "        # W_query is a linear function that maps a d_in dimensional vector\n",
        "        # to a d_out dimensional vector\n",
        "        # Mathematically, it is the same as a d_in by d_out matrix\n",
        "        # Same for the key and value\n",
        "        self.W_query = nn.Linear(d_in, d_out)\n",
        "        self.W_key = nn.Linear(d_in, d_out)\n",
        "        self.W_value = nn.Linear(d_in, d_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is B x N x d_in\n",
        "        # Q, K, and V are B x N x d_out\n",
        "        Q = self.W_query(x)\n",
        "        K = self.W_key(x)\n",
        "        V = self.W_value(x)\n",
        "\n",
        "        QKT = Q @ K.transpose(1, 2) # dim 1 is N, and dim 2 is d_out\n",
        "        A = torch.softmax(QKT / (self.d_out ** 0.5), dim=-1)\n",
        "\n",
        "        # A is B x N x N\n",
        "        # V is B x N x d_out\n",
        "        # A @ V is B x N x d_out\n",
        "        context_vector = A @ V\n",
        "        return context_vector"
      ],
      "metadata": {
        "id": "praoZVNx33aN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3:** Create a tensor representing a batch of 40 context windows, where each context window has 50 tokens and each token has embedding size 768. Pass it through the `SelfAttentionV2` module. Print the size of the output."
      ],
      "metadata": {
        "id": "m44VhCZ2bGN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "X_batch = torch.randn(40, 50, 768)\n",
        "self_attention = SelfAttentionV2(768, 1024) # calls __init__\n",
        "context_batch = self_attention(X_batch) # calls the forward function\n",
        "print(context_batch.shape)\n",
        "\n",
        "X_batch_2 = torch.randn(28, 50, 768)\n",
        "context_batch_2 = self_attention(X_batch_2) # calls the forward function\n",
        "# forward is generally called many times, while init is only called once\n",
        "print(context_batch_2.shape)\n",
        "\n",
        "# X_batch_3 = torch.randn(40, 50, 512)\n",
        "# context_batch_3 = self_attention(X_batch_3) # error\n",
        "# You cannot use a different embedding size with the same model\n",
        "# because the parameters of the model were already defined with a fixed embedding\n",
        "# size in mind\n",
        "\n",
        "#X_batch_4 = torch.randn(40, 35, 768)\n",
        "#context_batch_4 = self_attention(X_batch_4)\n",
        "#print(context_batch_4.shape)\n",
        "# no error, but may cause complications later if not careful\n",
        "# since we have QKT being a different size\n"
      ],
      "metadata": {
        "id": "Z0emwQlN54iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d95de20-f76c-457f-e308-12a80aefcad5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40, 50, 1024])\n",
            "torch.Size([28, 50, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4:** Create your own text (at least 10 words). Make a dataloader of the text with batch size 2, context size 4, and stride 1. Make input embeddings of size 768 (including both token and positional embeddings) and pass them through your SelfAttentionV2 module."
      ],
      "metadata": {
        "id": "kBQAd3hTcSqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset class\n",
        "class MyData(Dataset):\n",
        "    # Init function, called when the dataset is created\n",
        "    # dataset = MyData(text, tokenizer, context_length=4, stride=1)\n",
        "    def __init__(self, text, tokenizer, context_length, stride=1):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = tokenizer.encode(text)\n",
        "        for i in range(0, len(token_ids) - context_length, stride):\n",
        "            self.input_ids.append(torch.tensor(token_ids[i : i + context_length]))\n",
        "            self.target_ids.append(torch.tensor(token_ids[i + 1 : i + context_length + 1]))\n",
        "\n",
        "    # Length function\n",
        "    # len(dataset)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    # Get item function\n",
        "    # dataset[idx]\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# Dataloader\n",
        "def my_batch(text, batch_size, context_length, stride, shuffle=True, drop_last=True, num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create the dataset object\n",
        "    dataset = MyData(text, tokenizer, context_length, stride)\n",
        "\n",
        "    # Use the DataLoader library to create a dataloader that batches the data\n",
        "    dataloader = DataLoader(dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last=drop_last,\n",
        "                            num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "# Your code here\n",
        "my_text = \"I am currently taking a class about learning how to build LLMs\"\n",
        "loader = my_batch(my_text, batch_size=2, context_length=4, stride=1)\n",
        "vocab_size = 50257\n",
        "token_embs = nn.Embedding(vocab_size, 768)\n",
        "pos_embs = nn.Embedding(vocab_size, 768)\n",
        "model = SelfAttentionV2(768, 1024)\n",
        "context_embs = []\n",
        "for input, target in loader:\n",
        "  embedding = token_embs(input) + pos_embs(torch.arange(4))\n",
        "  context_emb = model(embedding)\n",
        "  context_embs.append(context_emb)\n",
        "  print(context_emb.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "zZYFMbFzcRj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11aa9ff8-6443-448f-9789-22fdc5be2e5b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 1024])\n",
            "torch.Size([2, 4, 1024])\n",
            "torch.Size([2, 4, 1024])\n",
            "torch.Size([2, 4, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optional: Building a bad minimal language model**"
      ],
      "metadata": {
        "id": "cWhK0qe5QpUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: B x N\n",
        "# After embedding: B x N x emb_dim\n",
        "# After self-attention: B x N x att_dim\n",
        "# What we want: B x N x vocab_size\n",
        "# This is an actually complete language model,\n",
        "# except it is way too small and doesn't have many of the ideas\n",
        "# that makes GPT actually work\n",
        "# Later on, we will actually build a functional GPT\n",
        "class BadLM(nn.Module):\n",
        "  def __init__(self, context_length, vocab_size, emb_dim, att_dim):\n",
        "    super().__init__()\n",
        "    self.context_length = context_length\n",
        "    self.emb_dim = emb_dim\n",
        "    self.att_dim = att_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.token_embs = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.pos_embs = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.att = SelfAttentionV2(emb_dim, att_dim)\n",
        "    self.prediction_layer = nn.Linear(att_dim, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x is B x N\n",
        "    embedding = self.token_embs(x) + self.pos_embs(torch.arange(self.context_length))\n",
        "    context_embedding = self.att(embedding)\n",
        "    prediction = self.prediction_layer(context_embedding)\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "kQDKWChdQmE2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = \"I am currently taking a class about learning how to build LLMs\"\n",
        "loader = my_batch(my_text, batch_size=2, context_length=4, stride=1)\n",
        "vocab_size = 50257\n",
        "model = BadLM(4, vocab_size, 768, 1024)\n",
        "predictions = []\n",
        "for input, target in loader:\n",
        "  output = model(input) # B x N x 50257\n",
        "  tokens = torch.argmax(output, dim=-1)\n",
        "  predictions.append(tokens)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaYFUNlqS3X8",
        "outputId": "2b05c43e-5192-4aed-fecc-5f92cf799b6b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[40685, 40523, 44613, 26037],\n",
            "        [ 6153, 18592, 18592, 18592]]), tensor([[27397, 10369, 17422, 17422],\n",
            "        [38761, 23733, 23733, 43100]]), tensor([[39077, 38761, 19789, 40304],\n",
            "        [ 9106, 26461, 18857, 26461]]), tensor([[20136, 38709, 47734, 50000],\n",
            "        [ 4756, 25881,  4756, 40461]])]\n"
          ]
        }
      ]
    }
  ]
}